{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Hedged Monte Carlo\n",
    "\n",
    "Author: Jerry Xia\n",
    "\n",
    "Date: 2018/06/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "This is a Python Notebook about variance reduction Monte Carlo simulations. In this script, I implemented the following variance reduction methods as well as their antithetic variates' version:\n",
    "\n",
    "* regular Monte Carlo\n",
    "* Monte Carlo with delta-based control variates\n",
    "* optimal hedged Monte Carlo\n",
    "\n",
    "Due to the significance and robustness, I mainly focus on the optimal hedged Monte Carlo (OHMC) in option pricing. We invoke this method to price European options and make comparison with other methods.\n",
    "\n",
    "### 1.1 Facts\n",
    "* The option price is not simply the average value of the discounted future pay-off over the objective (or historical) probability distribution\n",
    "* The requirement of absence of arbitrage opportunities is equivalent to the existence of \"risk-neutral measure\", such that the price is indeed its average discounted future pay-off.\n",
    "* Risk in option trading cannot be eliminated\n",
    "\n",
    "### 1.2 Objective\n",
    "* It would be satisfactory to have an option theory where the objective stochastic process of the underlying is used to calculate the option price, the hedge strategy and the *residual risk*.\n",
    "\n",
    "### 1.3 Advantages\n",
    "* It is a versatile methods to price complicated path-dependent options.\n",
    "* Considerable variance reduction scheme for Monte Carlo\n",
    "* It provide not only a numerical estimate of the option price, but also of the optimal hedge strategy and of the residual risk.\n",
    "* This method does not rely on the notion of risk-neutral measure, and can be used to any model of the true dynamics of the underlying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Underlying dynamics\n",
    "\n",
    "### Black-Scholes Model\n",
    "$$dS = \\mu S dt + \\sigma S dW_t$$\n",
    "$$log S_{t+1} = log S_t +(\\mu - \\frac{\\sigma^2}{2})\\Delta t + \\sigma \\sqrt{\\Delta t} \\epsilon$$\n",
    "where\n",
    "$$\\epsilon \\sim N(0,1)$$\n",
    "In risk neutral measure, $\\mu = r - q$. \n",
    "### Heston Model\n",
    "The basic Heston model assumes that $S_t$, the price of the asset, is determined by a stochastic process:\n",
    "$$\n",
    "dS_t = \\mu S_t dt + \\sqrt{v_t} S_t d W_t^S\\\\\n",
    "dv_t = \\kappa (\\theta - v_t) dt + \\xi \\sqrt{v_t} d W_t^v\n",
    "$$\n",
    "where \n",
    "$$E[dW_t^S,dW_t^v]=\\rho dt$$\n",
    "In risk neutral measure, $\\mu = r - q$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Methodology\n",
    "\n",
    "### 3.1 Simbol Definition\n",
    "Option price always requires to work backward. That is because the option price is known exactly at the maturity. As with other schemes, we determine the option price step by step from the maturity $t=K\\tau=T$ to the present time $t=0$. The unit of time being $\\tau$, for example, one day. We simulate $N$ trajectories. In trajectory i, the price of the underlying asset at time $k\\tau$ is denoted as $S_k^{(i)}$. The price of the derivative at time $k\\tau$ is denoted as $C_k$, and the hedge function is $H_k$. We define an optimal hedged portfolio as\n",
    "$$W_k^{(i)} = C_k(S_k^{(i)}) + H_k(S_k^{(i)})S_k^{(i)}$$\n",
    "The one-step change of our portfolio is\n",
    "$$\\Delta W_k^{(i)}= df(k,k+1) C_{k+1}(S_{k+1}^{(i)}) - C_k(S_k^{(i)}) + H_k(S_{k}^{(i)}) (df2(k,k+1) S_{k+1}^{(i)} - S_{k}^{(i)})$$\n",
    "Where $df(k,k+1)$ is the discounted factor from time $k\\tau$ to $(k+1) \\tau$, $df2(k,k+1)$ is the discounted factor considering dividend $e^{-(r-q)(t_{k+1}-t_k)}$\n",
    "\n",
    "### 3.2 Objective\n",
    "The optimal hedged algorithm can be interpreted as the following optimal problem\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{minimize}\\quad & \\quad Var[\\Delta W_k]\\\\\n",
    "\\mbox{subject to}\\quad & \\quad E[\\Delta W_k]=0\n",
    "\\end{align}\n",
    "\n",
    "It means we should try to minimize the realized volatility of hedged portfolio while maintaining the expected value of portfolio unchanged.\n",
    "\n",
    "### 3.3 Basis Functions\n",
    "The original optimization is very difficult to solve. Thus we assume a set of basis function and solved it in such subspace. We use $N_C$and $N_H$ to denote the number of basis functions for price and hedge.\n",
    "\n",
    "\\begin{align}\n",
    "C_k(\\cdot) &= \\sum_{i=0}^{N_C} a_{k,i} A_i(\\cdot)\\\\\n",
    "H_k(\\cdot) &= \\sum_{i=0}^{N_H} b_{k,i} B_i(\\cdot)\n",
    "\\end{align}\n",
    "\n",
    "The basis functions $A_i$ and $B_i$ are priori determined and need not to be identical. The coefficients $a_i$ and $b_i$ can be calibrated by solving the optimal problem.\n",
    "\n",
    "### 3.4 Numerical Solution\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{minimize}\\quad & \\quad \\frac{1}{N} \\sum_{i=1}^N \\Delta W_k^{(i)2}\\\\\n",
    "\\mbox{subject to}\\quad & \\quad \\frac{1}{N} \\sum_{i=1}^N \\Delta W_k^{(i)}=0\n",
    "\\end{align}\n",
    "\n",
    "Denote the discounted forward underlying price change at time $k\\tau$ as\n",
    "\n",
    "$$\\Delta S_k = df2(k,k+1) S_{k+1} - S_k$$\n",
    "\n",
    "Define\n",
    "\n",
    "\\begin{align}\n",
    "Q_k &= \\begin{bmatrix}\n",
    "    -A_{k,1}(S_k^{(1)}) & \\cdots & -A_{k,N_C}(S_k^{(1)}) & B_{k,1}(S_k^{(1)})\\Delta S_k^{(1)}& \\cdots  & B_{k,N_H}(S_k^{(1)})\\Delta S_k^{(1)} \\\\\n",
    "    -A_{k,1}(S_k^{(2)}) & \\cdots & -A_{k,N_C}(S_k^{(2)}) & B_{k,1}(S_k^{(2)})\\Delta S_k^{(2)}& \\cdots  & B_{k,N_H}(S_k^{(1)})\\Delta S_k^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "    -A_{k,1}(S_k^{(N)}) & \\cdots & -A_{k,N_C}(S_k^{(N)}) & B_{k,1}(S_k^{(N)})\\Delta S_k^{(N)}& \\cdots  & B_{k,N_H}(S_k^{(N)})\\Delta S_k^{(N)}\n",
    "    \\end{bmatrix}\\\\\\\\\n",
    "c_k &= (a_{k,1}, \\cdots a_{k,N_C}, b_{k,1}, \\cdots, b_{k,N_H})^T\\\\\\\\\n",
    "v_{k} &= df(k,k+1) C_{k+1}(S_{k+1}^{})\n",
    "\\end{align}\n",
    "\n",
    "As for $v_k$, note that we know the exact value at maturity, which means there is no need to approximate price in terms of basis functions, that is\n",
    "\n",
    "\\begin{align}\n",
    "v_k = \\begin{cases}\n",
    "df(N-1,N)\\ payoff(S_N),\\quad & k=N-1\\\\\n",
    "df(k,k+1)\\ \\sum_{i=1}^{N_C} a_{k+1,i} A_i(S_{k+1}), \\quad & 0<k<N-1\\\\\n",
    "df(0,1)\\ C_1(S_1), \\quad & k=0\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Then, the optimization problem can be expressed as\n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad (v_{k} + Q_k c_k)^T (v_{k} + Q_k c_k)\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T (v_{k}  + Q_k c_k)=0\n",
    "\\end{align}\n",
    "\n",
    "In step k, since we already know the information ($v_{k}$) in step k+1. By canceling the constant term, the optimal problem can be simplified as the following \n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad 2 v_{k}^T Q_k c_k + c_k^T Q_k^T Q_k c_k\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T v_{k}  + 1_{[N\\times1]}^T Q_k c_k=0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Convex Optimization Problem\n",
    "\n",
    "Let us first review the standard form of linear constrained quadratic programming problem:\n",
    "\n",
    "\\begin{align}\n",
    "    \\min_{x} \\quad & \\frac{1}{2} x^T P x + q^T x\\\\\n",
    "    \\mbox{subject to} \\quad &G x \\preceq h\\\\\n",
    "    &A x = b\n",
    "\\end{align}\n",
    "\n",
    "Note that $x^T$ means the transpose of vector x, and $G x \\preceq h$denotes the inequality is taken element-wise over the vectors $G x$ and $h$. The objective function is convex if and only if the matrix $P$ is positive-semidefinite(Hermitian matrix all of whose eigenvalues are nonnegative), which is the realm we concern with.\n",
    "\n",
    "Recall that the constrained optimization problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad  v_{k}^T Q_k c_k + \\frac{1}{2}c_k^T Q_k^T Q_k c_k\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T v_{k}  + 1_{[N\\times1]}^T Q_k c_k=0\n",
    "\\end{align}\n",
    "\n",
    "Correspondingly, we make the connection by letting\n",
    "\n",
    "\\begin{align}\n",
    "    x &= c_k\\\\\n",
    "    P &= Q_k^T Q_k\\\\\n",
    "    q &= Q_k^T v_k\\\\\n",
    "    A &= 1_{[N\\times1]}^T Q_k\\\\\n",
    "    b &= -1_{[N\\times1]}^T v_{k}\n",
    "\\end{align}\n",
    "\n",
    "The hard work is almost over right now. As you would always find, formulating the problem is usually the hard step. Invoking a solver is straightforward.\n",
    "\n",
    "Note that when $k=0$, the degree of freedom of the quadratic problem decreases to 2. Because here the only concerns are price and hedge at time zero (we don't need to project them into a high dimension space). Let $x=[C_0, H_0]^T$\n",
    "\n",
    "\\begin{align}\n",
    "    Q_0 &= \\begin{bmatrix}\n",
    "    -1 & \\Delta S_0^{(1)}\\\\\n",
    "    \\vdots & \\vdots\\\\\n",
    "    -1 & \\Delta S_0^{(N)}\n",
    "    \\end{bmatrix}\\\\\n",
    "    P &= Q_0^T Q_0\\\\\n",
    "    q &= Q_0^T v_0\\\\\n",
    "    A &= 1_{[N \\times 1]}^T Q_0\\\\\n",
    "    b &= -1_{[N \\times 1]}^T v_0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Variance reduction and other methods\n",
    "The rate of convergence of the Monte Carlo simulation is $O\\left(\\max \\left( \\Delta t, \\frac{1}{N_x} \\right)\\right)$. The variance reduction techniques are used to reduce the constant factor corresponding to the Monte Carlo approximation $O \\left(\\frac{1}{N_x}\\right)$. Some of the most used variance reduction techniques are:\n",
    "\n",
    "* Control Variates\n",
    "* Antithetic Variates\n",
    "* Moment Matching\n",
    "\n",
    "In this part we selected antithetic variates and delta-based control variates methods as a supplement to optimal hedged monte carlo simulation.\n",
    "\n",
    "### 4.1 Antithetic variates\n",
    "The main idea of this technique is to look at the asset equation that you aretrying to simulate:\n",
    "$$d S_t^{(1)} = r S_t^{(1)} dt + \\sigma S_t^{(1)} d W_t$$\n",
    "and recognize that sinceztis a standard Brownian motion so will beâˆ’ztandthey will have the same exact distribution.  This means that the equation:\n",
    "$$d S_t^{(2)} = r S_t^{(2)} dt - \\sigma S_t^{(2)} d W_t$$\n",
    "will also generate paths of the same asset.\n",
    "The variance depends on the sign of the covariance of $payoff(S_t^{(1)})$ and $payoff(S_t^{(2)})$. It can increase the eventual variance or decrease it, both case do arise. One sufficient condition to insure variance reduction is the monotony of the payoff function. Then, when using both in the calculation of the final Monte Carlo value the variance of the estimate will be reduced.\n",
    "\n",
    "### 4.2 Delta-based control variates\n",
    "Delta hedging can be summarized succinctly in the following way:  Suppose that at time $t= 0$, we receive $C_0$ the price of an option that pays $C_T$ at time T.  The price of this option at any time $t$ is a function $C(t,S)$. Then, if we hold at any moment in time $\\frac{\\partial C}{\\partial S}(t,S) = \\frac{\\partial C_t}{\\partial S}$ units of stock, then we will be able to replicate the payout of this option $C_T$ at time T. This is in theory since of course we cannot trade continuously. So in practice we perform a partial hedge where we only rebalance at some discrete moments in time say $t_1,t_2,\\cdots,t_N$. The replicating strategy can be expressed as follow:\n",
    "$$W(t_i,S_i) = C(t_0,S_0) e^{r(t_i - t_0)} + \\sum_{j=0}^{i} \\Delta(t_j,S_j) ( S_{j+1} e^{-r(t_{j+1} - t_j )} - S_{j})e^{r(t_i - t_j)} = C(t_i,S_i)$$\n",
    "which is similar to the strategy in the optimal hedged Monte Carlo simulation where the only difference is that in OHMC, we use option and delta hedging to replicate the cash flow and here we do the opposite operation. But when implementing the delta-based control variates, we should move the hedging term to the right hand side which make it identical to the OHMC strategy. Note that here we are assumed to know the delta hedging function. It explains a lot why OHMC can reduce the variance.\n",
    "\n",
    "### 4.3 Optimal hedged Monte Carlo simulation\n",
    "**In conclusion, OHMC is just a control variates method with an optimization on top and it is more practical because we do not have an analytical formula for the hedge sensitivity (i.e. delta, gamma, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from cvxopt import matrix, solvers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.0319\n",
    "dividend = 0\n",
    "time_to_maturity = 1\n",
    "volatility = 0.2\n",
    "strike = 100\n",
    "stock_price = 100\n",
    "V0 = 0.010201\n",
    "kappa = 6.21\n",
    "theta = 0.019\n",
    "xi = 0.61\n",
    "rho = -0.7\n",
    "\n",
    "n_trails = 1000\n",
    "n_steps = 200\n",
    "func_list = [lambda x: x**0, lambda x: x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MonteCarlo import MonteCarlo   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from cvxopt import matrix, solvers\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MonteCarlo:\n",
    "    def __init__(self,S0,K,T,r,q,sigma,kappa=0,theta=0,xi=0,rho=0,V0=0,underlying_process=\"geometric brownian motion\"):\n",
    "        self.underlying_process = underlying_process\n",
    "        self.S0 = S0\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.r = r\n",
    "        self.q = q\n",
    "        self.sigma = sigma\n",
    "        self.kappa = kappa\n",
    "        self.theta = theta\n",
    "        self.rho = rho\n",
    "        self.V0 = V0\n",
    "        self.xi = xi\n",
    "        \n",
    "        self.value_results = None\n",
    "    \n",
    "    # view antithetic variates as a option of simulation method to reduce the variance    \n",
    "    def simulate(self, n_trails, n_steps, antitheticVariates=False, boundaryScheme=\"Higham and Mao\"):\n",
    "        \n",
    "        dt = self.T/n_steps\n",
    "        mu = self.r - self.q\n",
    "        self.n_trails = n_trails\n",
    "        self.n_steps = n_steps\n",
    "        self.boundaryScheme = boundaryScheme\n",
    "        \n",
    "        if(self.underlying_process==\"geometric brownian motion\"):\n",
    "#             first_step_prices = np.ones((n_trails,1))*np.log(self.S0)\n",
    "            log_price_matrix = np.zeros((n_trails,n_steps))\n",
    "            normal_matrix = np.random.normal(size=(n_trails,n_steps))\n",
    "            if(antitheticVariates==True):\n",
    "                n_trails *= 2\n",
    "                self.n_trails = n_trails\n",
    "                normal_matrix = np.concatenate((normal_matrix,-normal_matrix),axis=0)\n",
    "            cumsum_normal_matrix = normal_matrix.cumsum(axis=1)\n",
    "#             log_price_matrix = np.concatenate((first_step_prices,log_price_matrix),axis=1)\n",
    "            deviation_matrix = cumsum_normal_matrix*self.sigma*np.sqrt(dt) + \\\n",
    "    (mu-self.sigma**2/2)*dt*np.arange(1,n_steps+1)\n",
    "            log_price_matrix = deviation_matrix+np.log(self.S0)\n",
    "            price_matrix = np.exp(log_price_matrix)\n",
    "            price_zero = (np.ones(n_trails)*self.S0)[:,np.newaxis]\n",
    "            price_matrix = np.concatenate((price_zero,price_matrix),axis=1)\n",
    "            self.price_matrix = price_matrix\n",
    "        \n",
    "        elif(self.underlying_process==\"CIR model\"):\n",
    "            # generate correlated random variables\n",
    "            randn_matrix_v = np.random.normal(size=(n_trails,n_steps))\n",
    "            if(antitheticVariates==True):\n",
    "                n_trails *= 2\n",
    "                self.n_trails = n_trails\n",
    "                randn_matrix_v = np.concatenate(( randn_matrix_v, -randn_matrix_v),axis=0)\n",
    "\n",
    "            # boundary scheme fuctions\n",
    "            if(boundaryScheme==\"absorption\"):\n",
    "                f1=f2=f3=lambda x: np.maximum(x,0)\n",
    "            elif(boundaryScheme==\"reflection\"):\n",
    "                f1=f2=f3=np.absolute\n",
    "            elif(boundaryScheme==\"Higham and Mao\"):\n",
    "                f1=f2=lambda x: x\n",
    "                f3 = np.absolute\n",
    "            elif(boundaryScheme==\"partial truncation\"):\n",
    "                f1=f2=lambda x: x\n",
    "                f3=lambda x: np.maximum(x,0)\n",
    "            elif(boundaryScheme==\"full truncation\"):\n",
    "                f1 = lambda x: x\n",
    "                f2=f3= lambda x: np.maximum(x,0)\n",
    "            \n",
    "            # simulate CIR process\n",
    "            V_matrix = np.zeros((n_trails,n_steps+1))\n",
    "            V_matrix[:,0] = self.S0\n",
    "\n",
    "            for j in range(self.n_steps):\n",
    "                V_matrix[:,j+1] = f1(V_matrix[:,j]) - self.kappa*dt*(f2(V_matrix[:,j])-self.theta) +\\\n",
    "                    self.xi*np.sqrt(f3(V_matrix[:,j]))*np.sqrt(dt)*randn_matrix_v[:,j]\n",
    "                V_matrix[:,j+1] = f3(V_matrix[:,j+1])\n",
    "                \n",
    "            price_matrix = V_matrix\n",
    "            self.price_matrix = price_matrix\n",
    "            \n",
    "        \n",
    "        elif(self.underlying_process==\"Heston model\"):\n",
    "            # generate correlated random variables\n",
    "            randn_matrix_1 = np.random.normal(size=(n_trails,n_steps))\n",
    "            randn_matrix_2 = np.random.normal(size=(n_trails,n_steps))\n",
    "            randn_matrix_v = randn_matrix_1\n",
    "            randn_matrix_S = self.rho*randn_matrix_1 + np.sqrt(1-self.rho**2)*randn_matrix_2\n",
    "            if(antitheticVariates==True):\n",
    "                n_trails *= 2\n",
    "                self.n_trails = n_trails\n",
    "                randn_matrix_v = np.concatenate(( randn_matrix_v, +randn_matrix_v),axis=0)\n",
    "                randn_matrix_S = np.concatenate(( randn_matrix_S, -randn_matrix_S),axis=0)\n",
    "\n",
    "            # boundary scheme fuctions\n",
    "            if(boundaryScheme==\"absorption\"):\n",
    "                f1=f2=f3=lambda x: np.maximum(x,0)\n",
    "            elif(boundaryScheme==\"reflection\"):\n",
    "                f1=f2=f3=np.absolute\n",
    "            elif(boundaryScheme==\"Higham and Mao\"):\n",
    "                f1=f2=lambda x: x\n",
    "                f3 = np.absolute\n",
    "            elif(boundaryScheme==\"partial truncation\"):\n",
    "                f1=f2=lambda x: x\n",
    "                f3=lambda x: np.maximum(x,0)\n",
    "            elif(boundaryScheme==\"full truncation\"):\n",
    "                f1 = lambda x: x\n",
    "                f2=f3= lambda x: np.maximum(x,0)\n",
    "            \n",
    "            # simulate stochastic volatility process\n",
    "            V_matrix = np.zeros((n_trails,n_steps+1))\n",
    "            V_matrix[:,0] = self.V0\n",
    "            log_price_matrix = np.zeros((n_trails,n_steps+1))\n",
    "            log_price_matrix[:,0] = np.log(self.S0)\n",
    "            for j in range(self.n_steps):\n",
    "#                 V_matrix[:,j+1] = self.kappa*self.theta*dt + (1-self.kappa*dt)*V_matrix[:,j] +\\\n",
    "#                     self.xi*np.sqrt(V_matrix[:,j]*dt)*randn_matrix_v[:,j]\n",
    "                V_matrix[:,j+1] = f1(V_matrix[:,j]) - self.kappa*dt*(f2(V_matrix[:,j])-self.theta) +\\\n",
    "                    self.xi*np.sqrt(f3(V_matrix[:,j]))*np.sqrt(dt)*randn_matrix_v[:,j]\n",
    "                V_matrix[:,j+1] = f3(V_matrix[:,j+1])\n",
    "                log_price_matrix[:,j+1] = log_price_matrix[:,j] + (mu - V_matrix[:,j]/2)*dt +\\\n",
    "                    np.sqrt(V_matrix[:,j]*dt)*randn_matrix_S[:,j]\n",
    "            price_matrix = np.exp(log_price_matrix)\n",
    "            self.price_matrix = price_matrix\n",
    "            \n",
    "        return price_matrix\n",
    "    \n",
    "    def BlackScholesPricer(self,option_type='c'):\n",
    "        S = self.S0\n",
    "        K = self.K\n",
    "        T = self.T\n",
    "        r = self.r\n",
    "        q = self.q\n",
    "        sigma = self.sigma\n",
    "        d1 = (np.log(S/K)+(r-q)*T +0.5*sigma**2*T)/(sigma*np.sqrt(T))\n",
    "        d2 = d1 - sigma*np.sqrt(T)\n",
    "        N = lambda x: sp.stats.norm.cdf(x)\n",
    "        call = np.exp(-q*T) * S * N(d1) - np.exp(-r*T) * K * N(d2)\n",
    "        put = call - np.exp(-q*T) * S + K*np.exp(-r*T)\n",
    "        if(option_type==\"c\"):\n",
    "            return call\n",
    "        elif(option_type==\"p\"):\n",
    "            return put\n",
    "        else:\n",
    "            print(\"please enter the option type: (c/p)\")\n",
    "        pass\n",
    "    \n",
    "    def MCPricer(self,option_type='c',isAmerican=False):\n",
    "        price_matrix = self.price_matrix\n",
    "        # k = n_steps\n",
    "        dt = self.T/self.n_steps\n",
    "        df = np.exp(- self.r*dt)\n",
    "        n_basis = len(func_list)\n",
    "        n_trails = self.n_trails\n",
    "        n_steps = self.n_steps\n",
    "        \n",
    "        if(option_type==\"c\"):\n",
    "            payoff = (price_matrix[:,n_steps] - strike)\n",
    "        elif(option_type==\"p\"):\n",
    "            payoff = (strike - price_matrix[:,n_steps])\n",
    "        else:\n",
    "            print(\"please enter the option type: (c/p)\")\n",
    "            return\n",
    "        \n",
    "        payoff = matrix(np.where(payoff<0,0,payoff))\n",
    "#         vk = payoff*df\n",
    "        value_results = payoff*np.exp(-risk_free_rate*time_to_maturity)\n",
    "        regular_mc_price = np.average(payoff*np.exp(-risk_free_rate*time_to_maturity))\n",
    "        self.payoff = payoff\n",
    "        self.mc_price = regular_mc_price\n",
    "        self.value_results = value_results\n",
    "        return regular_mc_price\n",
    "    \n",
    "    def BSDeltaHedgedPricer(self,option_type=\"c\"):\n",
    "        \n",
    "        regular_mc_price = self.MCPricer(option_type=option_type)\n",
    "        dt = self.T/self.n_steps\n",
    "        df = np.exp(- self.r*dt)\n",
    "        df2 = np.exp(-(self.r-self.q)*dt)\n",
    "        \n",
    "        # Delta hedged cash flow\n",
    "        def Delta_fun(x,tau,option_type):\n",
    "            d1 = (np.log(x/self.K) + (self.r-self.q)*tau + self.sigma**2*tau/2)/(self.sigma*np.sqrt(tau))\n",
    "            if(option_type=='c'):\n",
    "                return sp.stats.norm.cdf(d1)\n",
    "            elif(option_type=='p'):\n",
    "                return -sp.stats.norm.cdf(-d1)\n",
    "        \n",
    "        discounted_hedge_cash_flow = np.zeros(self.n_trails)\n",
    "        for i in range(self.n_trails):\n",
    "            Sk_array = self.price_matrix[i,:]\n",
    "            bi_diag_matrix = np.diag([-1]*(n_steps),0) + np.diag([df2]*(n_steps-1),1)\n",
    "            # (Sk+1 exp(-r dt) - Sk) exp(-r*(tk-t0))\n",
    "            discounted_stock_price_change = np.dot(bi_diag_matrix,Sk_array[:-1])\n",
    "            discounted_stock_price_change[-1] += Sk_array[-1]*df2\n",
    "            discounted_stock_price_change *= np.exp(-self.r*np.arange(n_steps)*dt)\n",
    "            tau_array = dt*np.arange(self.n_steps,0,-1)\n",
    "            Delta_array = np.array([Delta_fun(Sk,tau,option_type) for Sk,tau in zip(Sk_array[:-1],tau_array)])\n",
    "            discounted_hedge_cash_flow[i] = np.dot(Delta_array,discounted_stock_price_change)\n",
    "        \n",
    "        BSDeltaBased_mc_price = regular_mc_price - discounted_hedge_cash_flow.mean()\n",
    "#         print(\"The average discounted hedge cash flow: {}\".format(discounted_hedge_cash_flow.mean()))\n",
    "        \n",
    "        value_results = self.payoff*np.exp(-self.r*self.T) - discounted_hedge_cash_flow\n",
    "#         print(\"Sanity check {} = {}\".format(value_results.mean(),BSDeltaBased_mc_price))\n",
    "        self.value_results = value_results\n",
    "        \n",
    "        return BSDeltaBased_mc_price\n",
    "    \n",
    "    def OHMCPricer(self,option_type='c', func_list=[lambda x: x**0, lambda x: x]):\n",
    "        def _calculate_Q_matrix(S_k,S_kp1,df,df2,func_list):\n",
    "            dS = df2*S_kp1 - S_k\n",
    "            A = np.array([func(S_k) for func in func_list]).T\n",
    "            B = (np.array([func(S_k) for func in func_list])*dS).T\n",
    "            return np.concatenate((-A,B),axis=1)\n",
    "        \n",
    "        price_matrix = self.price_matrix\n",
    "        # k = n_steps\n",
    "        dt = self.T/self.n_steps\n",
    "        df = np.exp(- self.r*dt)\n",
    "        df2 = np.exp(-(self.r-self.q)*dt)\n",
    "        n_basis = len(func_list)\n",
    "        n_trails = self.n_trails\n",
    "        n_steps = self.n_steps\n",
    "        \n",
    "        if(option_type==\"c\"):\n",
    "            payoff = (price_matrix[:,n_steps] - strike)\n",
    "        elif(option_type==\"p\"):\n",
    "            payoff = (strike - price_matrix[:,n_steps])\n",
    "        else:\n",
    "            print(\"please enter the option type: (c/p)\")\n",
    "            return\n",
    "        \n",
    "        payoff = matrix(np.where(payoff<0,0,payoff))\n",
    "        vk = payoff*df\n",
    "#         print(\"regular MC price\",regular_mc_price)\n",
    "    \n",
    "        # k = 1,...,n_steps-1\n",
    "        for k in range(n_steps-1,0,-1):\n",
    "            Sk = price_matrix[:,k]\n",
    "            Skp1 = price_matrix[:,k+1]\n",
    "            Qk = matrix(_calculate_Q_matrix(Sk,Skp1,df,df2,func_list))\n",
    "            P = Qk.T * Qk\n",
    "            q = Qk.T * vk\n",
    "            A = matrix(np.ones(n_trails,dtype=np.float64)).T * Qk\n",
    "            b = - matrix(np.ones(n_trails,dtype=np.float64)).T * vk\n",
    "            sol = solvers.coneqp(P=P,q=q,A=A,b=b)\n",
    "            ak = sol[\"x\"][:n_basis]\n",
    "            bk = sol[\"x\"][n_basis:]\n",
    "            vk = matrix(np.array([func(price_matrix[:,k]) for func in func_list])).T*ak*df\n",
    "        \n",
    "        # k = 0\n",
    "        v0 = vk\n",
    "        S0 = price_matrix[:,0]\n",
    "        S1 = price_matrix[:,1]\n",
    "        dS0 = df2*S1 - S0\n",
    "        Q0 = np.concatenate((-np.ones(n_trails)[:,np.newaxis],dS0[:,np.newaxis]),axis=1)\n",
    "        Q0 = matrix(Q0)\n",
    "        P = Q0.T*Q0\n",
    "        q = Q0.T*v0\n",
    "        A = matrix(np.ones(n_trails,dtype=np.float64)).T * Q0\n",
    "        b = - matrix(np.ones(n_trails,dtype=np.float64)).T * v0\n",
    "        C1 = matrix(ak).T * np.array([func(S1) for func in func_list]).T\n",
    "        sol = solvers.coneqp(P=P,q=q,A=A,b=b)\n",
    "        self.sol = sol\n",
    "        residual_risk = (v0.T*v0 + 2*sol[\"primal objective\"])/n_trails\n",
    "        self.residual_risk = residual_risk[0]    # the value of unit matrix\n",
    "        \n",
    "        return sol[\"x\"][0]\n",
    "    \n",
    "    def standard_error(self):\n",
    "        # can not apply to the OHMC since its result is not obtained by averaging\n",
    "        # sample variance\n",
    "        sample_var = np.var(self.value_results,ddof=1)\n",
    "        std_estimate = np.sqrt(sample_var)\n",
    "        standard_err = std_estimate/np.sqrt(n_trails)\n",
    "        return standard_err\n",
    "        \n",
    "    def pricing(self, option_type='c', func_list=[lambda x: x**0, lambda x: x]):\n",
    "        OHMC_price = self.OHMCPricer(option_type=option_type,func_list=func_list)\n",
    "        regular_mc_price = self.MCPricer(option_type=option_type)\n",
    "        black_sholes_price = self.BlackScholesPricer(option_type)\n",
    "        return({\"OHMC\": OHMC_price,\"regular MC\": regular_mc_price,\"Black-Scholes\":black_sholes_price})\n",
    "    \n",
    "    def hedging(self):\n",
    "        S = self.S0\n",
    "        K = self.K\n",
    "        T = self.T\n",
    "        r = self.r\n",
    "        q = self.q\n",
    "        sigma = self.sigma\n",
    "        d1 = (np.log(S/K)+(r-q)*T +0.5*sigma**2*T)/(sigma*np.sqrt(T))\n",
    "        d2 = d1 - sigma*np.sqrt(T)\n",
    "        N = lambda x: sp.stats.norm.cdf(x)\n",
    "        return({\"OHMC optimal hedge\": -self.sol[\"x\"][1],\"Black-Scholes delta hedge\":N(d1),\"OHMC residual risk\":self.residual_risk})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_matrix = mc.simulate(n_trails=n_trails,n_steps=n_steps,boundaryScheme=\"absorption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.        , 100.17357613, 100.61906447, ..., 120.37337436,\n",
       "        121.88294535, 122.05241272],\n",
       "       [100.        , 100.19860262,  99.71159192, ...,  98.37872532,\n",
       "         98.12073471,  98.74444962],\n",
       "       [100.        , 101.45410174, 101.91962217, ..., 105.4713738 ,\n",
       "        105.29100833, 105.87377448],\n",
       "       ...,\n",
       "       [100.        , 100.4067306 , 101.99965438, ...,  96.67213928,\n",
       "         96.73269827,  96.66214321],\n",
       "       [100.        , 101.36552645, 101.91320076, ...,  82.9936487 ,\n",
       "         82.7617365 ,  83.15934592],\n",
       "       [100.        , 100.5189913 , 100.68789267, ..., 120.78683322,\n",
       "        120.7288506 , 120.74858936]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.883634473769376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.BSDeltaHedgedPricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.838647261981442"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.OHMCPricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OHMC': 6.838647261981442, 'regular MC': 7.221024631146839, 'Black-Scholes': 9.509529570134703}\n"
     ]
    }
   ],
   "source": [
    "prices = mc.pricing(func_list=func_list)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OHMC optimal hedge': 0.5557301745089136, 'Black-Scholes delta hedge': 0.6023752589899478, 'OHMC residual risk': -2.1827872842550278e-14}\n"
     ]
    }
   ],
   "source": [
    "hedges = mc.hedging()\n",
    "print(hedges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Methods Comparison\n",
    "\n",
    "In this part, we discuss the performance of OHMC and regular MC. The underlying stochastic process is Heston model. In the following, we compare the absolute error with respect to the Black-Scholes price corresponding to trajactories number and runtime. The result is displayed by scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_comparison(n_trails,n_steps,underlying_process=\"geometric brownian motion\"):\n",
    "    if(underlying_process==\"geometric brownian motion\"):\n",
    "        mc = MonteCarlo(stock_price,strike,time_to_maturity,risk_free_rate,dividend,volatility)\n",
    "        theoretical_value = mc.BlackScholesPricer()\n",
    "    elif(underlying_process==\"Heston model\"):\n",
    "        mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "        theoretical_value = 6.8061\n",
    "    \n",
    "    # black scholes\n",
    "    bs_start = timeit.default_timer()\n",
    "    bs_price = mc.BlackScholesPricer('c')\n",
    "    bs_sde_estimate = 'NA'\n",
    "    bs_rmse = 'NA'\n",
    "    bs_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC\n",
    "    rmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    rmc_price = mc.MCPricer('c')\n",
    "    rmc_sde_estimate = mc.standard_error()\n",
    "    rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC with antithetic variates\n",
    "    rmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    rmc_anti_price = mc.MCPricer('c')\n",
    "    rmc_anti_sde_estimate = mc.standard_error()\n",
    "    rmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # Delta-based MC\n",
    "    dbmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    dbmc_price = mc.BSDeltaHedgedPricer('c')\n",
    "    dbmc_sde_estimate = mc.standard_error()\n",
    "    dbmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    dbmc_end = timeit.default_timer()\n",
    "    \n",
    "    # Delta-based MC with antithetic variates\n",
    "    dbmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps)\n",
    "    dbmc_anti_price = mc.BSDeltaHedgedPricer('c')\n",
    "    dbmc_anti_sde_estimate = mc.standard_error()\n",
    "    dbmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    dbmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC\n",
    "    ohmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    ohmc_price = mc.OHMCPricer('c')\n",
    "    ohmc_sde_estimate = \"NA\"\n",
    "    ohmc_rmse = 'NA'\n",
    "    ohmc_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC with antithetic varietes\n",
    "    ohmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    ohmc_anti_price = mc.OHMCPricer('c')\n",
    "    ohmc_anti_sde_estimate = \"NA\"\n",
    "    ohmc_anti_rmse = 'NA'\n",
    "    ohmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    bs_runtime = bs_end - bs_start\n",
    "    rmc_runtime = rmc_end - rmc_start\n",
    "    dbmc_runtime = dbmc_end - dbmc_start\n",
    "    ohmc_runtime = ohmc_end-ohmc_start\n",
    "    rmc_anti_runtime = rmc_anti_end - rmc_anti_start\n",
    "    dbmc_anti_runtime = dbmc_anti_end - dbmc_anti_start\n",
    "    ohmc_anti_runtime = ohmc_anti_end-ohmc_anti_start\n",
    "    \n",
    "    bs_err = np.abs(bs_price - theoretical_value)\n",
    "    rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "    dbmc_err = np.abs(dbmc_price - theoretical_value)\n",
    "    ohmc_err = np.abs(ohmc_price - theoretical_value)\n",
    "    rmc_anti_err = np.abs(rmc_anti_price - theoretical_value)\n",
    "    dbmc_anti_err = np.abs(dbmc_anti_price - theoretical_value)\n",
    "    ohmc_anti_err = np.abs(ohmc_anti_price - theoretical_value)\n",
    "    \n",
    "    \n",
    "    result = {\"method\":[\"Black Scholes\",\"MC\",\"antithetic MC\",\"DBMC\",\"antithetic DBMC\",\"OHMC\",\"antithetic OHMC\"],\n",
    "              \"runtime\":[bs_runtime,rmc_runtime,rmc_anti_runtime,dbmc_runtime,dbmc_anti_runtime,\n",
    "                         ohmc_runtime,ohmc_anti_runtime],\n",
    "              \"err\":[bs_err,rmc_err,rmc_anti_err,dbmc_err,dbmc_anti_err,ohmc_err,ohmc_anti_err], \n",
    "              \"standard err estimate\":[bs_sde_estimate,rmc_sde_estimate,rmc_anti_sde_estimate,dbmc_sde_estimate,\n",
    "                              dbmc_anti_sde_estimate,ohmc_sde_estimate,ohmc_anti_sde_estimate],\n",
    "              \"root mean square error\":[bs_rmse, rmc_rmse, rmc_anti_rmse, dbmc_rmse, dbmc_anti_rmse, ohmc_rmse, ohmc_anti_rmse],\n",
    "              \"n_trails\":[n_trails]*7,\n",
    "              \"n_steps\":[n_steps]*7}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trials: 100; n_steps: 50\n",
      "n_trials: 100; n_steps: 100\n",
      "n_trials: 100; n_steps: 150\n",
      "n_trials: 600; n_steps: 50\n",
      "n_trials: 600; n_steps: 100\n",
      "n_trials: 600; n_steps: 150\n"
     ]
    }
   ],
   "source": [
    "n_trails_list = np.arange(100,1000,500)\n",
    "n_steps_list = np.arange(50,200,50)\n",
    "performance_df = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "    for n_steps in n_steps_list:\n",
    "        print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "        new_df = pd.DataFrame(performance_comparison(n_trails,n_steps,underlying_process=\"Heston model\"))\n",
    "        performance_df = pd.concat((performance_df,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>err</th>\n",
       "      <th>standard err estimate</th>\n",
       "      <th>root mean square error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_trails</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Black Scholes</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.000413</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.000314</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.000349</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.000350</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>2.703430</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">DBMC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.376716</td>\n",
       "      <td>0.610449</td>\n",
       "      <td>1.16174</td>\n",
       "      <td>11.6329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2.184725</td>\n",
       "      <td>0.480579</td>\n",
       "      <td>0.492202</td>\n",
       "      <td>12.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.898901</td>\n",
       "      <td>0.338847</td>\n",
       "      <td>1.13855</td>\n",
       "      <td>11.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>4.929068</td>\n",
       "      <td>0.412770</td>\n",
       "      <td>0.469374</td>\n",
       "      <td>11.5047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>1.214938</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>1.15142</td>\n",
       "      <td>11.5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>7.491571</td>\n",
       "      <td>0.251057</td>\n",
       "      <td>0.469756</td>\n",
       "      <td>11.5094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.498304</td>\n",
       "      <td>0.746174</td>\n",
       "      <td>7.44104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>0.327908</td>\n",
       "      <td>8.02546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.003493</td>\n",
       "      <td>1.064908</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>7.28303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.552803</td>\n",
       "      <td>0.337445</td>\n",
       "      <td>8.27727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.279479</td>\n",
       "      <td>0.755535</td>\n",
       "      <td>7.52267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.324523</td>\n",
       "      <td>7.9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">OHMC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.327349</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.611208</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.223810</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.035362</td>\n",
       "      <td>0.522209</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.414010</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.052703</td>\n",
       "      <td>0.142767</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">antithetic DBMC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.183191</td>\n",
       "      <td>0.946091</td>\n",
       "      <td>1.54942</td>\n",
       "      <td>15.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1.132995</td>\n",
       "      <td>0.488116</td>\n",
       "      <td>0.481336</td>\n",
       "      <td>11.8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.412251</td>\n",
       "      <td>0.424609</td>\n",
       "      <td>1.2298</td>\n",
       "      <td>12.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2.573778</td>\n",
       "      <td>0.293276</td>\n",
       "      <td>0.481302</td>\n",
       "      <td>11.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.660297</td>\n",
       "      <td>0.660859</td>\n",
       "      <td>1.04881</td>\n",
       "      <td>10.5068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3.655554</td>\n",
       "      <td>0.227163</td>\n",
       "      <td>0.458856</td>\n",
       "      <td>11.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">antithetic MC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.855357</td>\n",
       "      <td>8.53508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.302169</td>\n",
       "      <td>0.338227</td>\n",
       "      <td>8.28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.199483</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>7.66704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.340303</td>\n",
       "      <td>0.327038</td>\n",
       "      <td>8.01131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.258796</td>\n",
       "      <td>0.801313</td>\n",
       "      <td>7.97716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.012699</td>\n",
       "      <td>0.403178</td>\n",
       "      <td>0.331767</td>\n",
       "      <td>8.12984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">antithetic OHMC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.290363</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.451487</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.521907</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.111048</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.026893</td>\n",
       "      <td>0.350075</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.046783</td>\n",
       "      <td>0.290536</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   runtime       err standard err estimate  \\\n",
       "method          n_steps n_trails                                             \n",
       "Black Scholes   50      100       0.000493  2.703430                    NA   \n",
       "                        600       0.000413  2.703430                    NA   \n",
       "                100     100       0.000314  2.703430                    NA   \n",
       "                        600       0.000349  2.703430                    NA   \n",
       "                150     100       0.000350  2.703430                    NA   \n",
       "                        600       0.000248  2.703430                    NA   \n",
       "DBMC            50      100       0.376716  0.610449               1.16174   \n",
       "                        600       2.184725  0.480579              0.492202   \n",
       "                100     100       0.898901  0.338847               1.13855   \n",
       "                        600       4.929068  0.412770              0.469374   \n",
       "                150     100       1.214938  0.038224               1.15142   \n",
       "                        600       7.491571  0.251057              0.469756   \n",
       "MC              50      100       0.004061  0.498304              0.746174   \n",
       "                        600       0.005775  0.034241              0.327908   \n",
       "                100     100       0.003493  1.064908              0.724105   \n",
       "                        600       0.009369  0.552803              0.337445   \n",
       "                150     100       0.005071  0.279479              0.755535   \n",
       "                        600       0.015468  0.063593              0.324523   \n",
       "OHMC            50      100       0.008132  0.327349                    NA   \n",
       "                        600       0.014235  0.611208                    NA   \n",
       "                100     100       0.017001  0.223810                    NA   \n",
       "                        600       0.035362  0.522209                    NA   \n",
       "                150     100       0.031434  0.414010                    NA   \n",
       "                        600       0.052703  0.142767                    NA   \n",
       "antithetic DBMC 50      100       0.183191  0.946091               1.54942   \n",
       "                        600       1.132995  0.488116              0.481336   \n",
       "                100     100       0.412251  0.424609                1.2298   \n",
       "                        600       2.573778  0.293276              0.481302   \n",
       "                150     100       0.660297  0.660859               1.04881   \n",
       "                        600       3.655554  0.227163              0.458856   \n",
       "antithetic MC   50      100       0.002309  0.644800              0.855357   \n",
       "                        600       0.004060  0.302169              0.338227   \n",
       "                100     100       0.003022  0.199483              0.770305   \n",
       "                        600       0.007979  0.340303              0.327038   \n",
       "                150     100       0.004718  0.258796              0.801313   \n",
       "                        600       0.012699  0.403178              0.331767   \n",
       "antithetic OHMC 50      100       0.008316  0.290363                    NA   \n",
       "                        600       0.013135  0.451487                    NA   \n",
       "                100     100       0.016820  0.521907                    NA   \n",
       "                        600       0.026921  0.111048                    NA   \n",
       "                150     100       0.026893  0.350075                    NA   \n",
       "                        600       0.046783  0.290536                    NA   \n",
       "\n",
       "                                 root mean square error  \n",
       "method          n_steps n_trails                         \n",
       "Black Scholes   50      100                          NA  \n",
       "                        600                          NA  \n",
       "                100     100                          NA  \n",
       "                        600                          NA  \n",
       "                150     100                          NA  \n",
       "                        600                          NA  \n",
       "DBMC            50      100                     11.6329  \n",
       "                        600                      12.066  \n",
       "                100     100                       11.39  \n",
       "                        600                     11.5047  \n",
       "                150     100                     11.5137  \n",
       "                        600                     11.5094  \n",
       "MC              50      100                     7.44104  \n",
       "                        600                     8.02546  \n",
       "                100     100                     7.28303  \n",
       "                        600                     8.27727  \n",
       "                150     100                     7.52267  \n",
       "                        600                      7.9428  \n",
       "OHMC            50      100                          NA  \n",
       "                        600                          NA  \n",
       "                100     100                          NA  \n",
       "                        600                          NA  \n",
       "                150     100                          NA  \n",
       "                        600                          NA  \n",
       "antithetic DBMC 50      100                       15.52  \n",
       "                        600                     11.8003  \n",
       "                100     100                     12.3029  \n",
       "                        600                      11.793  \n",
       "                150     100                     10.5068  \n",
       "                        600                     11.2419  \n",
       "antithetic MC   50      100                     8.53508  \n",
       "                        600                     8.28343  \n",
       "                100     100                     7.66704  \n",
       "                        600                     8.01131  \n",
       "                150     100                     7.97716  \n",
       "                        600                     8.12984  \n",
       "antithetic OHMC 50      100                          NA  \n",
       "                        600                          NA  \n",
       "                100     100                          NA  \n",
       "                        600                          NA  \n",
       "                150     100                          NA  \n",
       "                        600                          NA  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_efficiency_df = performance_df.set_index(['method','n_steps','n_trails']).sort_index()\n",
    "sorted_efficiency_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Variance Reduction Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thie section, we test more case and visualize the empirical error. Note that we do not concern Delta-based MC simulation since we cannot convert it to a matrix form, as a result, the method involes for-loop which is not efficient (see the form above). Moreover, the hypothesis which we know the delta hedge function is not realistic in practice. The result shows as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_comparison2(n_trails,n_steps,underlying_process=\"geometric brownian motion\"):\n",
    "    if(underlying_process==\"geometric brownian motion\"):\n",
    "        mc = MonteCarlo(stock_price,strike,time_to_maturity,risk_free_rate,dividend,volatility)\n",
    "        theoretical_value = mc.BlackScholesPricer()\n",
    "    elif(underlying_process==\"Heston model\"):\n",
    "        mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "        theoretical_value = 6.8061\n",
    "    \n",
    "    # black scholes\n",
    "    bs_start = timeit.default_timer()\n",
    "    bs_price = mc.BlackScholesPricer('c')\n",
    "    bs_sde_estimate = 'NA'\n",
    "    bs_rmse = 'NA'\n",
    "    bs_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC\n",
    "    rmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    rmc_price = mc.MCPricer('c')\n",
    "    rmc_sde_estimate = mc.standard_error()\n",
    "    rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC with antithetic variates\n",
    "    rmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    rmc_anti_price = mc.MCPricer('c')\n",
    "    rmc_anti_sde_estimate = mc.standard_error()\n",
    "    rmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC\n",
    "    ohmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    ohmc_price = mc.OHMCPricer('c')\n",
    "    ohmc_sde_estimate = \"NA\"\n",
    "    ohmc_rmse = 'NA'\n",
    "    ohmc_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC with antithetic varietes\n",
    "    ohmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    ohmc_anti_price = mc.OHMCPricer('c')\n",
    "    ohmc_anti_sde_estimate = \"NA\"\n",
    "    ohmc_anti_rmse = 'NA'\n",
    "    ohmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    bs_runtime = bs_end - bs_start\n",
    "    rmc_runtime = rmc_end - rmc_start\n",
    "    \n",
    "    ohmc_runtime = ohmc_end-ohmc_start\n",
    "    rmc_anti_runtime = rmc_anti_end - rmc_anti_start\n",
    "    \n",
    "    ohmc_anti_runtime = ohmc_anti_end-ohmc_anti_start\n",
    "    \n",
    "    bs_err = np.abs(bs_price - theoretical_value)\n",
    "    rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "    \n",
    "    ohmc_err = np.abs(ohmc_price - theoretical_value)\n",
    "    rmc_anti_err = np.abs(rmc_anti_price - theoretical_value)\n",
    "    \n",
    "    ohmc_anti_err = np.abs(ohmc_anti_price - theoretical_value)\n",
    "    \n",
    "    \n",
    "    result = {\"method\":[\"Black Scholes\",\"MC\",\"antithetic MC\",\"OHMC\",\"antithetic OHMC\"],\n",
    "              \"runtime\":[bs_runtime,rmc_runtime,rmc_anti_runtime,\n",
    "                         ohmc_runtime,ohmc_anti_runtime],\n",
    "              \"err\":[bs_err,rmc_err,rmc_anti_err,ohmc_err,ohmc_anti_err], \n",
    "              \"standard err estimate\":[bs_sde_estimate,rmc_sde_estimate,rmc_anti_sde_estimate,\n",
    "                                       ohmc_sde_estimate,ohmc_anti_sde_estimate],\n",
    "              \"root mean square error\":[bs_rmse, rmc_rmse, rmc_anti_rmse, ohmc_rmse, ohmc_anti_rmse],\n",
    "              \"n_trails\":[n_trails]*5,\n",
    "              \"n_steps\":[n_steps]*5}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trials: 100; n_steps: 150\n",
      "n_trials: 600; n_steps: 150\n",
      "n_trials: 1100; n_steps: 150\n",
      "n_trials: 1600; n_steps: 150\n",
      "n_trials: 2100; n_steps: 150\n",
      "n_trials: 2600; n_steps: 150\n",
      "n_trials: 3100; n_steps: 150\n",
      "n_trials: 3600; n_steps: 150\n",
      "n_trials: 4100; n_steps: 150\n",
      "n_trials: 4600; n_steps: 150\n",
      "n_trials: 5100; n_steps: 150\n",
      "n_trials: 5600; n_steps: 150\n",
      "n_trials: 6100; n_steps: 150\n",
      "n_trials: 6600; n_steps: 150\n",
      "n_trials: 7100; n_steps: 150\n",
      "n_trials: 7600; n_steps: 150\n",
      "n_trials: 8100; n_steps: 150\n",
      "n_trials: 8600; n_steps: 150\n",
      "n_trials: 9100; n_steps: 150\n",
      "n_trials: 9600; n_steps: 150\n"
     ]
    }
   ],
   "source": [
    "n_trails_list = np.arange(100,10000,500)\n",
    "# n_steps_list = np.arange(50,200,50)\n",
    "performance_df2 = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "#     for n_steps in n_steps_list:\n",
    "    print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "    new_df = pd.DataFrame(performance_comparison2(n_trails,n_steps,underlying_process=\"Heston model\"))\n",
    "    performance_df2 = pd.concat((performance_df2,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAELCAYAAAAhuwopAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd0lNXWh58zJb1nUoAAoUoNXaOigoIiTQQLWBArWD57ARXkWq71WhAVQVGxIRYUEFGRKkVAg3QktCRAep3UKef7481MMumBTBLMedZikXnLeXeyktmz2+8IKSUKhUKhUNQHXVMboFAoFIqzD+U8FAqFQlFvlPNQKBQKRb1RzkOhUCgU9UY5D4VCoVDUG+U8FAqFQlFvlPNQKBQKRb1RzkOhUCgU9UY5D4VCoVDUG0NTG1BfTCaTjI6ObmozFAqF4qzizz//TJdShjXUemed84iOjmbHjh1NbYZCoVCcVQghjjfkeiptpVAoFIp6o5yHQqFQKOqNch4KhUKhqDdnXc1DoWhJWCwWkpKSKCoqampTFGcJXl5eREVFYTQa3foc5TwUimZMUlIS/v7+REdHI4RoanMUzRwpJRkZGSQlJdGhQwe3PkulrRSKZkxRURGhoaHKcSjqhBCC0NDQRolUlfNQKJo5ynEo6kNj/b60GOdxIPMAn+37DLXtrkKhUJw5LcZ5/HHqD17e/jJmi7mpTVEoFKX4+fmd0f1DhgyhXbt2Lh8Kx40b57LuP//8w8iRI+ncuTPdu3fnuuuuIyUl5Yyeq2hBzsPkbQIgrTCtiS1RKM5OpJTY7fZm9/ygoCA2bdoEQHZ2NqdOnXKeKyoqYtSoUdx9993Ex8ezf/9+7r77btLS1PvAmdLinEdGYUYTW6JQnD0cO3aM7t27c88999C/f38SExP55ZdfOP/88+nfvz/XXnstZrMWza9cuZJu3boxePBg7r//fkaPHg3A7Nmzee2115xr9urVi2PHjrk8x2w2c9lll9G/f3969+7NDz/8UO3zKzJx4kQWL14MwHfffcf48eOd57744gvOP/98xowZ4zw2dOhQevXq1TA/oBaMW1t1hRAjgLcAPfCBlPKlCuffAIaWvvQBwqWUQe6wJcxb0wNLL0x3x/IKhdv5z/K97DuZ26Br9mgdwDNjetZ4zcGDB/noo4949913SU9P5/nnn2f16tX4+vry8ssv8/rrr/P4448zdepUNmzYQIcOHZg0aVK97PDy8mLp0qUEBASQnp5ObGwsY8eOrfT8qrjsssu48847sdlsLF68mPnz5/Pcc88BsGfPHgYMGFAvWxR1w23OQwihB94BhgNJwHYhxDIp5T7HNVLKh8pd/39AP3fZE+odCkBagQpXFYr60L59e2JjYwHYunUr+/bt48ILLwSgpKSE888/nwMHDtCxY0fnbMGkSZOYP39+nZ8hpeTJJ59kw4YN6HQ6Tpw44axLlH9+Vej1egYPHsxXX31FYWEhSnW7cXBn5HEuEC+lPAIghFgMXAXsq+b6ScAz7jImwCMAD50H6UUq8lCcndQWIbgLX19f59dSSoYPH86XX37pck1cXFy19xsMBpdaRVUzCJ9//jlpaWn8+eefGI1GoqOjndeVf351TJw4kauvvprZs2e7HO/Zsyfr16+v9X5F/XFnzaMNUD5BmVR6rBJCiPZAB2CNu4wRQmDyNqmah0JxBsTGxrJp0ybi4+MBKCgo4J9//qFbt24cOXLEWcv46quvnPdER0fz119/AfDXX39x9OjRSuvm5OQQHh6O0Whk7dq1HD9eP/Xwiy66iBkzZlRKl91www1s3ryZH3/80Xls1apV7N69u17rKyrjTudR1aRKdUMWE4FvpJS2KhcS4i4hxA4hxI4z6ZIweZtU2kqhOAPCwsL4+OOPmTRpEjExMcTGxnLgwAG8vb159913GTFiBIMHDyYiIoLAwEAAJkyYQGZmJn379uW9996ja9eulda98cYb2bFjBwMHDuTzzz+nW7du9bJLCMGjjz6KyWRyOe7t7c2KFSt4++236dKlCz169ODjjz8mPDz89H8ICgCEu4bmhBDnA7OllFeUvp4BIKV8sYpr44B7pZSba1t34MCB8nQ3g7p/zf0kmZP4bux3p3W/QtHY7N+/n+7duze1GXXCbDbj5+eHlJJ7772XLl268NBDD9V+o6LBqer3Rgjxp5RyYEM9w52Rx3agixCigxDCAy26WFbxIiHEOUAwsMWNtgCotJVC4UYWLFhA37596dmzJzk5OUydOrWpTVK4EbcVzKWUViHEfcDPaK26C6WUe4UQzwI7pJQORzIJWCwbQTckzDuMzKJMLHYLRp175YoVipbGQw89pCKNFoRb5zyklCuBlRWOzarwerY7bSiPo103szCTCN+Iet1bsH07ae++S7v58xFu1slXKBSK5k6LmTCHsinz02nXNW/aRMGWrVjKSR8oFApFS6VFOQ/HlPnp1D2sKakAWJKTG9QmhUKhOBtpUc7DKY54Gu261pTk0v9TG9QmhUKhOBtpUc7DUfM4HX0rS6nTcDgRhUJRNd9//z379pUJScyaNYvVq1cD8Oabb1JQUOA8V19J9nXr1rF5c1lH/7x581i0aNEZWtwwtDR5+RblPDz0HgR6Bp6W87CWpqssyWofAIWiJio6j2effZZhw4YBlZ1HfanoPKZNm8bkyZPrvY6Slz9zWpTzADB5mertPGxmM/b8fEBFHoqWx7hx4xgwYAA9e/Z0ETv08/Pjqaeeok+fPsTGxpKSksLmzZtZtmwZjz32GH379uXw4cNMmTKFb775hjlz5nDy5EmGDh3K0KFDnetUXAMgLS2NCRMmMGjQIAYNGsSmTZs4duwY8+bN44033qBv375s3LjRRe49Pj6eYcOG0adPH/r378/hw4ddvg8lL9+wuLVVtzli8q6/87CWCwstquahaCp+mg7JDazJFNkbrnypxksWLlxISEgIhYWFDBo0iAkTJhAaGkp+fj6xsbG88MILPP744yxYsICnn36asWPHMnr0aK655hqXde6//35ef/111q5d65QRqW6NBx54gIceeojBgweTkJDAFVdcwf79+5k2bRp+fn48+uijAPz222/O9W+88UamT5/O1VdfTVFRUZWf7JW8fMPR4pxHqHcou9J21eseR4eVsX07Z/pKoWgpzJkzh6VLlwKQmJjIoUOHCA0NxcPDw/mJfMCAAfz666/1Xru6NVavXu2S+srNzSUvL6/adfLy8jhx4gRXX301oL2BV4WSl284WpzzCPMOI70wHSklQlSl3VgZR4eVd0wfclesQFosalBQ0fjUEiG4g3Xr1rF69Wq2bNmCj48PQ4YMcUqlG41G59+QXq/HarXWe/3q1rDb7WzZsgVvb+86rVNXgQolL99wtLyah7eJIlsR+Zb8Ot/jqHN49+4NUmJNV3uCKFoGOTk5BAcH4+Pjw4EDB9i6dWut9/j7+1cbJdR0rjyXX345c+fOdb7euXNnjfcHBAQQFRXF999/D0BxcXGthXklL39mtDjncTrtupaUFPRBQXi0bwe41kAUin8zI0aMwGq1EhMTw8yZM2tMuTiYOHEir776Kv369atUtL7rrru48sorXQrmVTFnzhx27NhBTEwMPXr0YN68eQCMGTOGpUuXOgvm5fn000+ZM2cOMTExXHDBBSTXkmJW8vJnhtsk2d3FmUiyA2w9tZU7f7mTj674iIGRdVMnTpx2N5bkZFq//BJHrxpHmzffJGDEFadtg0JRV84mSfZ/E2e7vPzZLsneLDF5lepb1SfySE3BEBGOodTDq3ZdheLfjZKXr50WVzB3iiPWw3lYk1Pw7tUbfVAQwtNTDQoqFP9ylLx87bS4yCPQMxCDzlBn52EvKcGWmYkhIhwhBIbICFXzUCgULZ4W5zyEENpe5oV1G+m3pmptusbISO3/iEgsynkoFIoWTotzHqDVPeoqy+4YCjRERJb+H6EGBRUKRYunZToPn7pLlDiiDGOEViw3RkZgSU1FNqGomkKhUDQ1LdN51CdtVVocN0Q6Io9IsFiwZWW5zT6FormRlJTEVVddRZcuXejUqRMPPPAAJSUlrFu3zikv4sAhhAhnn8y4ou641XkIIUYIIQ4KIeKFENOrueY6IcQ+IcReIcQX7rTHgcnbRFZRFlZ77XIK1tQUhI8PutJfdmOktve52lFQ0VKQUjJ+/HjGjRvHoUOH+OeffzCbzTz11FN1uv9skhlX1B23OQ8hhB54B7gS6AFMEkL0qHBNF2AGcKGUsifwoLvsKY/Jy4REklVUe/RgSU7BGBHh1N8xRGjOQ3VcKVoKa9aswcvLi1tvvRXQNKjeeOMNFi5cWKe9Oc4mmXFF3XHnnMe5QLyU8giAEGIxcBWwr9w1dwLvSCmzAKSUjaJ3bvIp3Y62MI0wn7Aar7WmpDgdBijnoWg6Xt72MgcyDzTomt1CuvHEuU/UeM3evXsrSYEHBATQrl074uPj2bhxI3379nWeS0hIcEllnU0y44q6407n0QYov9tJEnBehWu6AgghNgF6YLaUcpUbbQLqNyhoSUnB99xzna8NoaFgMKhBQUWLoToFasfxiy66iBUrVjiPT5kyxeW6s0lmXFF33Ok8qtI7ryikZQC6AEOAKGCjEKKXlDLbZSEh7gLuAmjXrt0ZG+ZwHrW160qbDWtamkvkIfR6DGFhql1X0ejUFiG4i549e/Ltt9+6HMvNzSUxMZFOnTrVaY2zRWZcUXfcWTBPAtqWex0FnKzimh+klBYp5VHgIJozcUFKOV9KOVBKOTAsrOY0U12oa+RhzcgAqxVDZITLcWNEhBoUVLQYLrvsMgoKCli0aBEANpuNRx55hClTpuDj41OnNc4WmXFF3XGn89gOdBFCdBBCeAATgWUVrvkeGAoghDChpbGOuNEmADz1nvh7+NfaruvYBMoY4eo8DJGRquahaDEIIVi6dClff/01Xbp0oWvXrnh5efHf//63XmucDTLjirrjtrSVlNIqhLgP+BmtnrFQSrlXCPEssENKuaz03OVCiH2ADXhMSlm30e8zpC57mTvUcx3T5Q6MERGYN2yo126ECsXZTNu2bVm+fHml40OGDGHIkCEuxz7++GPn1+vWratyPbPZ7Py6W7durFrl9lKnooFxq6qulHIlsLLCsVnlvpbAw6X/GpUw77Baax7O6fIKaStDRASyoAB7Xh76gAC32ahQKBTNlRY5YQ7ajoK1pq2SU8BoRB8S4nJcDQoqFIqWTot1HnVJW1lSkjGGhSF0rj8mh1SJoyaiUCgULY0W7TwKrYUUWKqfkLWmpLq06TowOgcFVeShUChaJi3WeYR5ay2/NaWurMnJldp0AQyl7cJqUFChULRUWqzzCPUOBaqf9ZBSYklNxRhe2XkIDw/0JpOKPBQKRYulxTqP2gYF7bm5yMJCZ32jImpQUKGomu+//559+8ok7GbNmsXq1asBePPNN13EFMtLs9eFdevWsXnzZufrefPmOYcX60J10vKOtZW8fN1psc7DkbaqznlU3ASqIobISOdeHwqFooyKzuPZZ59l2LBhQGXnUV8qOo9p06YxefLkOt17ptLyoOTly9NinUegZyAGYajWeTgmyKuPPMJV5KFoEYwbN44BAwbQs2dP5s+f7zzu5+fHU089RZ8+fYiNjSUlJYXNmzezbNkyHnvsMfr27cvhw4edn97nzJnDyZMnGTp0KEOHDnWuU3ENgLS0NCZMmMCgQYMYNGgQmzZt4tixY8ybN4833niDvn37snHjRmbPns1rr70GQHx8PMOGDaNPnz7079+fw4cPu3wfZyotD0pevjxuHRJszuiEjhDvkFqdR0VpEgeGiEjsOTnYCwvReXu7zU6FwkHyf/9L8f6GlWT37N6NyCefrPGahQsXEhISQmFhIYMGDWLChAmEhoaSn59PbGwsL7zwAo8//jgLFizg6aefZuzYsYwePZprrrnGZZ3777+f119/nbVr1zplSqpb44EHHuChhx5i8ODBJCQkcMUVV7B//36mTZuGn58fjz76KAC//fabc/0bb7yR6dOnc/XVV1NUVIS9wlbRtUnLA0pevh60WOcBWuqq2rSVY/vZaoQYHYOC1pQUPJTEtOJfzJw5c1i6dCkAiYmJHDp0iNDQUDw8PJxvrAMGDODXX3+t99rVrbF69WqX1Fdubi55eXnVrpOXl8eJEye4+uqrAfDy8qp0TW3S8oCSl68HLdp5mLxNpBRUnXqypqSgN5kQHh5VnnfMf1iSlfNQNA61RQjuYN26daxevZotW7bg4+PDkCFDKCoqAsBoNDrfdPV6PVZr7ds6V6S6Nex2O1u2bMG7jlF9+SJ2ddQmLZ+RUTdZPSUvr9Fiax5Q85S5JSUZYw3KngY1KKhoAeTk5BAcHIyPjw8HDhxg69attd7j7+9fbZRQ07nyXH755cydO9f5eufOnTXeHxAQQFRUFN9//z0AxcXFleoYDSEtD0pe3kGLdh6h3qFkFmVis9sqnbMmp1RbLIeyWohFSZQo/sWMGDECq9VKTEwMM2fOJDY2ttZ7Jk6cyKuvvkq/fv0qFa3vuusurrzySpeCeVXMmTOHHTt2EBMTQ48ePZg3bx4AY8aMYenSpc6CeXk+/fRT5syZQ0xMDBdccAHJFbTnGkJa3rGOkpcHUZdwrzkxcOBAuWPHjgZZa/GBxbzwxwusvW6tc+7DwT/nxeI/8kpaPfNMtfcfPC+WwFGjiJw1s0HsUSgqsn//frp3797UZijOMqr6vRFC/CmlHNhQz2jRkUd1g4L2oiJsOTkYI6qPPACM4apdV6FQtEyU86Cy83DOeFTTputAGxRUNQ+FQtHyUM4DSCtwnQB1tOlW3ASqIsbICCypKvJQuJezLbWsaFoa6/elRTsPhzhiRpFri541tY6RR0QktvQMZKk2jkLR0Hh5eZGRkaEciKJOSCnJyMiocs6loWnRcx7eBm/8jH6V0laOHQINVSjqlscQEQ5SYk1Lw9imjdvsVLRcoqKiSEpK+tfqIykaHi8vL6Kiotz+HLc6DyHECOAtQA98IKV8qcL5KcCrwInSQ3OllB+406aKVDXrYU1JRefvj97Pt8Z7jaWtvJaUFOU8FG7BaDTSoUOHpjZDoaiE25yHEEIPvAMMB5KA7UKIZVLKfRUu/UpKeZ+77KgNk7epUs3DmpKsRRW1UDYoqOoeCoWiZeHOmse5QLyU8oiUsgRYDFzlxuedFiZvU6WahyUltdY2XSgXeShpdoVC0cJwp/NoAySWe51UeqwiE4QQu4QQ3wgh2la1kBDiLiHEDiHEjobO/VaZtkpOrrVYDqDz90d4e6t2XYVC0eJwp/OoLF8JFVtGlgPRUsoYYDXwSVULSSnnSykHSikHhlWjcnu6mLxN5FvyKbBoOjjSasWanl5rmy5oMgVqR0GFQtEScafzSALKRxJRwMnyF0gpM6SUxaUvFwCNLobvmPXIKNRSV9b0dLDbK3daHd0AH40Cq2tbriEyUtU8FApFi8OdzmM70EUI0UEI4QFMBJaVv0AI0arcy7HAfjfaUyXOKfMiLXXlSEEZKkYe//wMx3+H7ASXw9qOgiptpVAoWhZu67aSUlqFEPcBP6O16i6UUu4VQjwL7JBSLgPuF0KMBaxAJjDFXfZUR8Upc4dKbqUdBNMPaf/nJICps/OwISISa2oa0m5H6Fr0zKVCoWhBuHXOQ0q5ElhZ4discl/PAGa404baqKhv5difo5Ice0ap88hOdDlsiIwAqxVbRka1uw4qFArFv40W/1E52CsYvdA7nYclJQXh4YE+KKjsImsJZB3Xvs5JcrlftesqFIqWSIt3HjqhI9QrtCzySE7BEBHhutdx1jGQpRtG5VSIPMLVjoIKhaLl0eKdB2gCiWVpq5TK9Q5HysroWylt5WjpVZGHQqFwJ+sOppJd0HxEWJXzwHVQ0JKSUnlA0FEsjx6sFczLoQ8JAaNRtesqFAq3cSqnkCkfbef7uBO1X9xIKOdBqURJoSZ7bU1Jqdymm3EIfMMgoifknoRye54Lna50R8F/d9oq/49tnJw+A1teXlObolC0OOISsgHo1y64iS0po0VLsjtw6FtZMrW9OSqnrQ5DaBcIjAK7FfKSIbBMacUQEYH1X5y2yl76PadmzgSrFUNYGOGPPNzUJikULYq4hCw8DDq6twpoalOcqMgDzXnYpI3MxHhAm91wIf2QNtsR1E57nVO57vFvjDyklKTNmcOpGTPwGTQQ/+HDyVy0CMvJk7XfrFAoGoy4hGx6twnEw9B83rKbjyVNiGPWIzvxMKBNjTspzIKC9NLIo1RtpeKsR0Qk1pTUf9Vub/aSEk4+9jjp775H4ITxtJs/n4jpT4CUpL31VlObp1C0GEqsdnafyKFf26DaL25ElPMAwny04T7zCW2Ww2VAMF2LRjB1gaBS51GhaG6ICEcWFWHPyXG7rY2BNSuLhNtuI3fFCsIefJBWzz+PMBoxtmlDyC2TyflhGYV79za1mQpFi+BAci7FVnuzqneAch4AmLy0yKMo+QTodBhMprKTjjbd0M7g4QveIVW065btKHi2U3L8OMcn3UDR37to/dprmKZNdZl5Cb3rLvRBQaS+8uq/KtJSKJorZcVyFXk0O0K9QwFt+1mDyYQwlOsjyIgHnQGCo7XXgVGVpsydOwqe5ft6FPwVx7GJk7BlZ9Pu448IHD2q0jV6f39M991HwR9/YF6/vgmsVChaFnEJWUQEeNIq0KupTXFBOQ/Ax+iDr9EXkZZZWdMq/ZDmOPRG7XVQuyoK5md/5JG7ciUJU6agDwggevGX+AyoXh0/+Prr8GjfntRXX0NarY1opULR8ohLzKZf22BX1YtmgHIepZi8TRgzcl2L5aBFHqFdyl4HttXSVuVSNgaTCYQ4K9t1pZSkvz+fEw8/glfv3rRf/CUe0dE13iOMRsIefYSSw4fJ/ubbxjFUoWiBZJiLOZ5R0OxSVqCch5NQr1C8swpd23TtNm3Go5wEO0FtwZKvdWGVIoxGDCbTWdeuKy0WTs2cSdobbxAwahTtFn6IIbhuRTn/YcPwHjCAtLffxmbOd7OlCkXLZGdi8xsOdKCcRymRIgivIhuG8pFHTiLYirViuYPAKO3/CptCGSIjz6rIw5aXR+LUqeR88y2hd0+j9WuvovP0rPP9QggiHn8MW0YGmQs/dKOlioYgp8DCg4vjOJxmbmpTFPUgLiEbvU7Qu01gU5tSCeU8Smlb7AOU1S+AsjbdimkrqEKaPQJr6tnhPCwnTnD8hhvI37adVi+8QPgDD5xWPtW7Tx8CRo4kY+FHtdZ7Sqx2Nh5KO12TFWfIhkNpfL/zJJM/3EZKblFTm6OoI3GJWXRv5Y+3h76pTamEch6lRORrHVa20HK5xYxyMx4OqpkyN4RHnBXKuoW793B04kQsySm0+2ABQRPGn9F6YQ8/BDYbaW/NqfG6H3ef5OYPt/HHkYwzep7i9Nh9IgejXpBVUMItC7eRW2RpapMUtWCzS/5OzKFf2+aXsgLlPJyElOr9mYM8yg5mHALPQE0U0YFPKBi8q9xR0J6Xhz2/+eb/8377jeM334zOw5PoL7/ANzb2jNf0iIoi+KabyFm6lKIDB6q97lCKli5ZvktJmzQFu5Ny6NEqgHk3DSA+1cxdi3ZQZLHVfqOiyYhPNWMutjbLYjko5+EkKEdrOc30L5e+cWhalU/pCKEVzStMmZe166a63dbTIX/rVpLu+z88u3Yl+qvFeHbuXPtNdcQ0bSq6gABSX32t2muOZWhOddWeZKw2e4M9W1E7drtkz8kcekcFcnHXMF67tg9bj2Ty8JKd2Oxq0LO5EpegNeU0x2I5uNl5CCFGCCEOCiHihRDTa7juGiGEFEIMdKc9NeGTVUSeF6Tbc8sOZsS7Fssd1DQo2Ew7rnK+/wFdQADtP/nYdYK+AdAHBhJ2z93kb9qEeePvVV5zJC0fHw896eYS/jia2aDPV9TM8cwC8oqszqLruH5teGpkd1buTuY/y/cqpYBmSlxCNkE+RqJDfZralCpxm/MQQuiBd4ArgR7AJCFEjyqu8wfuB/5wly11wSPTTEYAzk2hKMmH3BOuxXIHjlmPcjhk3Jtj3UPabJjXrcPvkovReXu75RnBkyZhbNuW1FdeQdpc0yF2u+R4RgHj+rXB10PPCpW6alR2n9A013qV69i58+KO3HlRBxZtOc676w43lWmKGohLzKJf26BmNxzowJ2Rx7lAvJTyiJSyBFgMXFXFdc8BrwBN2gIi0jLJ8hekFZZ2BGWU/kGZqog8gtpqSrslBc5DzTnyKNy5E1t2Nv5Dh7rtGcLDg/BHHqb40CFyli51OZeSV0ShxUb3SH+G9Yhg1Z5kLCp11WjsTsrGw6Cja4S/y/EZV3ZnXN/WvPrzQZZsT6zmbkVTkFtk4VCqudmmrMC9zqMNUP43Mqn0mBMhRD+grZRyRU0LCSHuEkLsEELsSEtzT7unNTWV/CAvMgpLu4GcgohVRR6Ojquy1JXOywt9UFCzlCgxr10LRiO+gwe79Tn+V1yBd58+pL01B3tBmWM9mq7VOzqY/BjVuxVZBRY2H1ZdV43F7hM5dG8VgFHv+ueu0wleuaYPF3UxMWPpbn7b3/x+d1squxJzkLL5iSGWx53Oo6pYy5lcFULogDeAR2pbSEo5X0o5UEo5MCwsrLbL640sKcGWnk5JiH9Z2so549Gp8g3VSrM3zx0F89asxXfQQPT+/rVffAYIIQh/4gmsaWlkfPSR87jDeUSbfLjknDD8PQ2s+FulrhoDu12y90QuvdtUvQOdh0HHezcNoEerAO794i/+PJ5V5XWKxiUuIQshoE8z28OjPO50HklA23Kvo4Dy7xj+QC9gnRDiGBALLGuKorm1NJqxhwWVS1sd0mobxipqBI4p84pF82a4o2DJsWOUHDmC39BLG+V5Pv374X/FFWR8uBBLqtZ5diw9Hw+DjtaB3nga9AzvGcHPe5MpsarUlbs5lpFPXrGVmDbVvwn5eRr46NZBRAR4cfsn24lPVVPoTU1cYjadw/wI8DI2tSnV4k7nsR3oIoToIITwACYCyxwnpZQ5UkqTlDJaShkNbAXGSil3uNGaxnZnAAAgAElEQVSmKnGkmvTh4eUij0NVd1oB+LcGoa+iaN78JEry1q4DwM+N9Y6KhD/8ENJiIf3tuYAWeUSH+qDTacHo6JhW5BZZ+T1eTZy7m6qK5VVh8vNk0W3nYtAJblm4jeQcNYXeVEgpiUvIatYpK6iD8xBC6IQQ19V3YSmlFbgP+BnYDyyRUu4VQjwrhBhbf1Pdh7XUeXi2ak1mYSZ2pyBiFfUOAL0BAlpXnjKPjMCWmYm9pMTdJtcZ85o1eHbtikdUm9ovbiA82rcneNJEsr/9luJDhziank8Hk6/z/ODOYQR6G1nx96lGs6mlsjspB0+Dji4RfrVe2z7Ul49vPZfs0in0nEI1hd4UHM8oIKvA0qyL5VAH5yGltKM5gXojpVwppewqpewkpXyh9NgsKeWyKq4d0hRRB5S11/q2botVWsnJjIeSvKqL5Q5qaNe1pjaPQUFbdjYFf/2F36WNF3U4MN19NzpfX5JffY2EzAI6mMrevDwMOq7oGcEv+1LUlLObqa5YXh292gTy/s0DOZJu5k41hd4kxCU6hgPP8sijlF+FEI8KIdoKIUIc/9xqWSNiTUlBeHsTbNJqGWnJcdqJqtp0HQS1rRx5lMq5N5cdBc0bN4LNhv+ljVPvKI8hOBjTtGkUbNhAz1MH6WByHXQaFdMac7GVDf+o1JW7sNsle0/m1luRdXAXE/+7ri/bjmby4GI1hd7YxCVk4+uhp0u4extczpS6Oo/bgHuBDcCfpf+aJEpwB5aUZIwREZh8tE6u9PT92onqah6gFc1zT4KtbCc9Y2TzGhQ0r12LPsyEV69eTfL84JtuxBYeyR17VtAh2LXx4IJOoQT7GFmxS6Wu3MXRjHzMxVZ6R9Vfzntsn9bMHN2DVXuTeWbZHjWF3ojEJWTTp20Qel3zHA50UKeaB3CTlLJDhX8dG8G+RsGakoohIgKTtybbkZF1RBM/DIiq/qbAtiBtkFf25ufYwtbaDGY9ZEkJ5g0b8R8yBKFrGgkznacnR8ZNplPuSSK3r3U5Z9TrGNGrFav3p1BYolIj7mBPabH8dPeCuH1wB6Ze3JHPtiYwd018Q5qmqIbCEhv7T+U2+5QV1L3mUb3i3b8Aa3IyxsgIwry1yCPNfFKb76jpTdc561GWutL7+aHz8WkW7boFO3ZgN5sbrUW3Ov7sMID4kHYUv/8e9sJCl3OjY1pRUGJj3cHmUSP6t+EslofXXiyvjidGdGN8vzb879d/WLwtofYbFGfEnpM5WO2y2cqwl6euH0l/EUJMEM1VZOUMkHY7ltRUDOER+Bh98DZ4k16YVnPKCsqmzCtJszePdt28tesQnp74nn/msutnwpHMQn655DqsyclkfrLI5dx5HUIw+Xmo1JWb2HUihx6tAzDUsVheFTqd4OVrYri4axhPLt3NL3ub/oPRvxmHkm7ff0PkUcrDwBKgWAiRK4TIE0Lk1nZTc2JzfDrP/LCHn/cmu7Qg2jIzwWrFUFqvMHmFkm7Jr75N14FzULBCx1UzGBSUUmJeswbfCy5wmxBiXTmWkQ8x/fEbdhkZ8+dTklD26dWg13Flr1b8diCF/GJrDaso6os2WZ7TINuXGvU63ruxP72jgrjvyzi2KGkZtxGXkE27EB9MfnXfErqpqKvzCASmAM9LKQOAnsBwdxnlDuLTzCzZkcTUT/+k37O/cNU7m3hl1QF27DgIlLXZhhn9SNfrao88PHy0jaGq6LiyNvGeHsX/HMJy4gR+Q4c0rR1WGyeyCukQ6kPEE08gPDxIuP0O50Q/wKiYVhRZ7Kw5oFJXDcmR9HzyS2wNtve1r6eBj6cMol2ID3cu2sHupJwGWVfhSlxC9llR74C6O4930ORDJpW+zgPmusUiNzH5/Gj+fuZyvrorlvsu7YJRJ3h/wxHe+HITAP/ZmsY7a+PxKhGk6/U1z3g4qGLWwxARjjUtDWltuk/S5rVacdpvyJAmswEgMbMAu4QOYb54tG1L2/fnYU1PJ+GuqdjytK0bB0WHEO7v6XaZdmm3U3zkSIvpGnIWy0+j06pKcpIIXvckn1/flkBvI7d8tI3DaWePjImUkpzly10EO5sbp3IKSc4tol8z1rMqT12dx3lSynsplU2XUmYBHjXf0vzwMOg4r2MoDw/vyjd3X8Dfz1zOQ320P64E4cerPx8kPSmbdL2eB1bn8cnmY8Sn5lX/hlPFrIcxMhJsNqwZTRfa561dg1dMDMbw8CazAbQNoACiQ7Xpcu8+fYiaM4fiQ4dIuude7MXF6HWCkb1bsfZgGnlu2ldbWiycfPwJjowcRcb7893yjObG7hM5eBl1dA47/WK5k5wk+Hg0bF9AxOZn+fT2cxHA5A+3cSqnsNbbmwP5v2/i5GOPk7X4q6Y2pVriErKB5rtzYEXq6jwspZs7SQAhRBhw1qva+Xka6CgKwWDgq+kj2fH0MM4LFOTpdexIKeaZZXsZ9voGYl/8jYe/2slPu0+5OpLAdlrkUe5Y2b4eTVM0t6alUbRrN/5NnLKCsq1ny0uT+F00mNYvvUTB9u2cfPRRpM3G6JhWlFjt/La/4VNX9qIikv7vfnJXrMCrRw/S3nyTzM8/b/DnNDcce5afSbEcKHMcBRnQawLsXUrHgt18ctu55BRauPnDbWTmNx85nurIXbEcAPP69U1sSfXEJWThYdDRvVXVCsjNjbr+Zs0BlgLhQogXgN+B/7rNqkbEmpyMISwModdj8vOki9TC2iX39mLDY0N5cXxvBkaHsO6fNO7+/C/e+u1Q2c1BbcFaCAVl26qW7SjYNEVz8/r1ICV+TTBVXpGj6fkE+xgJ8nENUgNHjyLiySfJ+3U1ybP/Q7+2QbQK9Grw1JXNbCbxzrswr19P5OxniF7yFX6XXUbKc8+Ts6ySQs6/BptdsvdkAxTLc5Lg41Ga47h5KYydCwFtYNV0erXy54NbBpKQWcCtH23D3IwbHuyFheT9uhphNFLw55/Ycptnr09cQja92wTiYWiauaz6UicrpZSfA48DLwKngHFSyq/daVhjYUlNcb7hA4Tmam/66YXptAv1YdK57Xjnhv5sf2oY1wyI4s3Vh3h3XenAlLPjqlwHkWNQsInadfPWrMXYujWeXbs2yfPLU1EQsTwhk28mdNpUsr/+moy35zCqdyvW/5PWYGJ81qwsEm6ZQkFcHK1ffZXgiRMRBgNtXv8fPrGxnJzxJHm//dYgz2puHE03a8XyqDPInTsdR6bmOKIGak0iw/4Dp3bC318Q2zGUd27oz56TuUz9dAfF1uY57Jm3Zg32ggJM994DViv5mzY1tUmVKLHa2X0i56ypd0A9JNmllAeklO9IKedKKfe706jGxJqc4nzDpyATU4HWZ+2UZi9FrxO8PCGGsX1a88qqg3yw8YhWMAeXork+OBhhNDZJu669qIj8zZvxGzq0Wex7fDQ9n+hqnAdA2AMPEHTttWTMe5+xhzdisUl+3XfmTteSksLxm26mOD6eqLlvEzh6lPOcztOTqLlz8erVkxMPPkT+li1n/Lzmxu4znCwnO7Gy43DQ+xqIGgS/PQvFeQzvEcErE2LYFJ/RbHWwcpctxxAZSejtt6MPDMS8bl1Tm1SJA8m5FFvt1dY7ZEkJSfdMoyAurpEtq56zIz5yE1JKLCkpGCNKC8sZhwmzaZ+e0gvSK12v1wlev64PV/aK5Pkf9/OVI4NVrmguhNAGBZugXTd/yxZkUVGTqOhWsqXYSkpuMR1rcB5CCCJnP4P/8GEY33uT8Zl7zjh1VXL8OMdvuBFrcjLtPliAfxUdZ3o/X9q9/z4e0dEk3nsfhX//fUbPbG7sTsrFy6ijU1j1P/tqyU6ET0aXOo7vXR0HgBAw4mUwp8DG1wGYMCCKp0d156c9yTy1dHez6mizZmVh3rSJgFEjEUYjvpdcjHnDRqSteUVJZcXyqiOPtLf+R96a9di2Lm5Ms2qkRTsPu9mMLChwquGScYhgmx2BIL2osvMAbbDtrYn9GNY9nCd+SsKi9666XbcJah7mNWvR+friO2hQoz+7ImXF8pq7fYReT+vXXsNn0CBu//1T8n//nazTLMAWHTzIsRtvwl5QQLtPPsGn3M+h2FbMz8d+xmLX0mL6oCDafvgBBpOJhLumUnTwn9N6ZnNk94lserYOrFQszy3JrfmNvZLjGFD1dVEDIGYibHkHso4BcMdFHblvaGcWb0/klZ8PNtB3cubk/vQTWK0EjtW2EPK75BJsWVkU7trVxJa5EpeQRbi/J60CvSqdK9y1i4yPPiWwQwH+E6Y0vnHV0KKdh+MN3uCIPNIPYdAZCPYKrpS2Ko+HQcc7N/bn4q7hHLOEcOL4IZfzxohI5+6EjYW02zGvW4fvRRchPJq+i/pYutZ4EF1Bir0qdJ6eRL37DqJDJ2Zs/YSNy9bV+3kFcXEcv3kyQq+n/Wef4t2rp8v5hXsW8uj6R/lg9wfOY8bwcNotXIjO05OEO253mX4/W7FVIcN+NOcoD659kAu/vJDh3wxn1qZZrDq2ipzicoN+zlRVVs2Ow8GwZ0Cnh19nOQ89cnlXbjivHe+tO8z8DYcb+ls7LXKXr8CzSxe8zjkHAL/Bg0Gvx7yueXVdxSVqw4EV0832oiJOTp+BwQciRnWE8O5NZGFlWrTzsJSmloyRZZEHwdGEeYdVmbYqj6dBz/ybB5Dv3YrMk/Es/7ss3WKIjMCaktKo4XvR3r1Y09LwbwYpK9CKtlA241Eben9/uny0ALNPAG1eeYriw3V/88nfvJmE225HHxxE+88/x7NTJ5fzBZYCvtj/BQZhYP6u+RzMLPtk7BHVhnYLPwSLlYRbb2t0p9/QHE03U1A6WZ5emM7zW5/n6h+uZsvJLUzuMZmYsBhWH1/NY+sf4+KvLubGH29k7pb/EvfpSKyF2aU1jlocB2g7aQ5+CPb9AMd+B7Q05HNX9WJUTCv+u/IAS7Yn1rKIeylJSqIwLo6AMWOcx/SBgfj079+s6h4Z5mKOZxRUWe9Ie+NNSo4cofXANPSxk5vAuupp0c7DmuKIPEq7rdLjIbQLJm9TjZGHAy+jnp49etFen8mDX+1k1R5tPWNEJLKkBFt2tttsr4h57VrQ6fC96KJGe2ZNHE0vICLAE19PQ53vMYaHs/vBZym2C47ddgeWU7ULJub++iuJU6fh0a4d0Z99VuV2u98d+o7s4mzeGPoGAR4BzNw005m+AvDs3Jm2CxZgy84m4bbbsWZl1dnmelHopnXLsSspB0Qx+4u+ZdR3o/j2n2+5pus1/Dj+Rx4b9BivD3mdDRM38OmVnzI1ZirYSlhw8EsmB8DF7SJ56NBnLDm4hBPmE7U/7IL/05pGVk0Hu1ZD0OsEb1zXl4u6mJj+3S5+bkIhxdwVKwAIHDXS5bjfkCEUHzyI5aR7VQ3qys7E0npHhU6r/G3byFy0iOAL2uEbpYde45vCvGpxq/MQQowQQhwUQsQLIaZXcX6aEGK3EGKnEOJ3IUQPd9pTEcenTEN4uPbLn3kETJ0J9Q6ttuZREWNIOwJkLgNbe/J/X/7FmgMpZYOCjVj3yFuzFp/+/TEEN4/p1KPp5mrbdGti6NABPH3+HVhyc0m4484a38izv1vKiQcexKtnT9ov+gRDWFilayw2Cx/v/ZgBEQMY0nYIT8c+zf7M/Xy852OX67x79yLqvXexJCWReMed2MwNLL1xZB28HA2/PecyVNqQWO1Wfjj8LX6dX+Or+A+4sM2FLL1qKU/HPu3cqwbAoDPQN7wv90SP5vMjB9mQnMP/et/L5R1GsidjD89tfY4R345gzNIxvPjHi6xPXE+BpQpZD6M3DP8PJO+GuM+chz0MOt6/eQB92gbxf1/Esflw3f6WGhJNjmQF3gMHYGzj+oHCoflm3rCh0e2qiriEbPQ64SIlYzPnc2rGkxjbRhEevQ96XAVeDSQ100C4zXmUTqS/A1wJ9AAmVeEcvpBS9pZS9gVeAV53lz1VYU1OQR8Sgs7DQ+uYshW7RB51SjuVSrN/cFUE3SIDmPbZX+wp0RQxG2tQ0HLiBMUHDjSLwUAHxzIKTst5dG/lD1268tno/8OSmEjStLur1CPKXLSIU08+iW9sLO0Wfog+sOo/rBVHVpBSkMIdve8AYHj74VwRfQXv/f0e8VmuGxz5nnsubd56k6KDB7XnFhXV2/5q+etTQMDG12DlY2BvOIEGKSVrE9Yyftl4/ir4AB8RzqdXfsrrQ14nOjC66puyE7TJ8cJsAm9eyuX9pzH7gtn8MuEXfrjqBx4f9DhR/lF8d+g77ltzHxcuvpCpv04ltaBCF2HP8dA2FtY8B0Vlw3c+HgY+mjKIaJMPd36yg11JjReFAxTv30/J4cMEjh5T6ZxHhw4Y27bFvHZdo9pUHXGJWXSL9MfHoyxKT335ZSynTtH6zsvR2XOh301NaGHVuDPyOBeIl1IekVKWAIuBq8pfIKUsP+rpS6n8SWNhTUlxSrGTXvpGYupCmHcYVrvVtaBYHaWDgv5FySy67Vw6mnx5dP1J5/qNQV5p/rapVXQdZBeUkJlfclrOQwjB6JjWLLGG4fv8ixTu3k3Sgw8iLVqaSUpJ2ttzSfnvi/gPH07UvPfQ+VRdlLfZbSzcs5DuId25sPWFzuNPnvckfkY/Zm6aidXuOhntP2QIrV9+iYI//yTpgQeQJQ0gvVGcBwd+hIG3aqme7Qvg+2lgO/OByF1pu5iyagr3r70fu7RjO3ULV4Y+T9/wvtXflJ2gFccLs2HyUmhTVuMQQtAxqCM397iZ94a9x++Tfmf+8Pnc1P0mdiTvYG5cBT1UIWDEi5CfpjnGcgT5eLDotvMI9vVgykfbiU9tPCHFnGXLwWgkYMQVlc4JIfAbMoT8rVsrbVDW2Njskr8Tc1xadM0bNpD99deE3nYrPgXrITga2l9Y/SJNhDudRxugfMUsqfSYC0KIe4UQh9Eij/vdaE8ltBmPcsVygNDOzhC/LnWPsh0FEwj29eCzO87DLzISm9CRcPBYwxtdBeY1a/Ho0AHPDh0a5Xm1cTTdVRCxvoyOaYVdwtqwHkT+Zzb5GzZy8qmnkDYbKS++SPo77xA4fjxt3nhdixqrYU3iGo7lHuO23re5dLGEeIXwZOyT7MnYwyd7P6l0X+CoUUTOnk3++g2cnD79zGcCDvyoydjEXA/Dn4NLZ8Kur2DJZLCcXnRzPPc4D697mBtX3sjx3OPMjJ3Jq7GfUpDdnT41TSk7HUdOJcdRFZ56T85vfT6PDHyE67tdz7LDyziWc8z1ojb9oe+NsPU9LfVbjshALz69/Tx0SJ589VtSct3/Zi1tNnJ//BG/iy9GH1T1z8JvyCXI4mLyt251uz01EZ9qxlxsde4caMvO5tRTT+PZpTOmm8fC0Q3az7aJtpKuCXdaVNWIc6XIonRqvRPwBPB0lQsJcZcQYocQYkdaub0gzhRrSopLmy6egeAbRqh3qHaoLnUP/1agMzhnPUx+nnx21/nkegewact+ZzHMXdjMZvK3bcNvaPPosoKyGY+OpzOkBnSN8KdrhB8r/j5F8LXXEvbgg+QuW86RMWPJWvQpIbdMptXzzyEM1RfjpZR8sPsD2ge0Z3i7ylvPXNH+Coa1G8a7O9/lSPaRSueDr7+O8MceJXflTyT/59kz65zb9RUEtYO252mf1C9+FEa+BgdXwufXaJFJHckozOC/f/yXcd+P4/cTv3N3n7tZOX4l151zHftOaj/3aifLXRzH97U6jorc3ut2PPQevPf3e5VPXjoTdEb4ZWalU22Kslm0/zP+s/wlNr4yr17PPB0Ktm3DmpZG4JjR1V7jM2gQOh+fJhdKdOwc6Ig8kp9/AWtWFq1ffhndvm8AAX0m1bBC0+FO55EEtC33Ogqoqb1hMTCuqhNSyvlSyoFSyoFhVRRFTwd7cTG2rKxybbrxYOoMQpTtZV5QB0el02tti+WmzMMDvDB1iCKiJJfJH/7h3FvhjKniDSz/901gsTSbFl2Ao2n56AS0Dal9xqM6Rse0ZvvxTJJzigidehfBk2+m5MgRTP93H+HTpyNq+SS25dQW9mXs49aet6LX6SudF0LwVOxTeBu9mbl5JjZ75egi9PbbCb3rLrKXLCH1tddOz4HkpWjF8t7XaY7Dwbl3wtXz4fhmWHSVi7hmVaQXpvP+3+8zaukolhxcwvgu41k5fiX39L0HH6P2c959IgcfDz0dq5JhT9xWwXH0r/e3Euodyg3dbuCnoz9xKMt1tomAVnDRw3BghfZpGW32KPOLLzg6diz6A3vJDI4gasWXWMz59X52fchZvgKdr2+N+9noPDzwvfBCzOvWN+lEfFxCNoHeRjqYfMld9TO5K1ZguuduvLqdA3GfQ6ehZdmNZoY7ncd2oIsQooMQwgOYCLhImQohyu+4NAqo8BvpPqypWuHPEF5a88iId24A5UhbZRTWcU+OwHaakFw5fNq0pqexCH8vIzd/+AcHks9QyfOfn+G1LnDKVUrDvHYN+qAgvPvWkONuZI5mFNAm2BtPQ+U37boyKqYVUsKPu08hhCBixgw6r/mNsHvvrZNu14e7PyTcO5wxnSoXTB2YvE3MOHcGu9J28dn+z6q8JuyhBwmaNJHMDxeSMX9B/b+RPd+CtEPMdZXP9bkerv8MkvfARyMh17U1OasoiyUHl3DHz3dw2deXMXfnXM6LPI/vrvqOmefPdOmgAs159GwdgF5X7ueTlwJL74YPh4PNetqOw8GtvW7F1+jLuzvfrXzy/Pu0v4VVMyg5dpSEW6aQ8uxzePftS8flyyh86EkCi/L4++3T+DnWEXtxMXm//IL/5Zej86o8rV0evyGXYE1Opvhg003ExyVm0a9dELaMDJJnz8arVy9Md94JR9dDblKzLJQ7cJvzkFJagfuAn4H9wBIp5V4hxLNCiLGll90nhNgrhNiJtk/6Le6ypyKONlpjZASU5EPuCS3yAHyNvnjpvepW8wCtaF5JoiQCkZ7GF3eeh4dBx00f/HFmBcNDv2pFyS8mQq4WwEmrFfP6DfhdcnGNKZzG5mi6+bTrHQ46hfnRvVUAP5ZqXQkhMLZuXad7d6XtYlvyNib3nIyHvuZp+5EdRjKk7RDejnu7ci6/9LmRM2cSMHo0aW+8QdIDD9Zp/sTJ7iXQqg+EnVP1+W4j4aZvtMj1oxHkJO9m6aGlTP11KkOXDOW5rc+RUpDCnb3vZOnYpbx16Vt0DOxYaRmbXbLvZC69HCkrmwW2vAtzB8Lur7WBvvu2n5HjAAj0DGRyj8msTljN3oy9rieNXsjLZpO54ShHxo6laP9+Wj3/HG0//ABjmzZcNP4y4lp1R//VZ86dJBsa89p12M3mGlNWDvwuvli7p4kGBnOLLBxKNdMvKohTs57BXlBA65deRBiNWtThFQTnjKp9oSbCrVUYKeVKKWVXKWUnKeULpcdmSSmXlX79gJSyp5Syr5RyqJRyb80rNhyO6XJDRIQWdYBz33IhBCZvE2mFdayvBLWFvJMu3TPGyAjs+flEeUq+uDMWEExasJU/jpzmDoMn/4KQTlCcC19cD8VmCnfuxJadjd/Q5tOiK6XkWHpBjYKIdWV0TCviEjI5mZIKOScqRXfV8eHuDwnwCOCartfUeq0Qglmxs/DQezBr86wq01dCp6P1i/8l7IH7Ma9fz+GRo0h/fz722jqx0g/ByTgtZVUDeW36sXz4E9zrVcKQVZOYtXkWCbkJTOk5ha/HfM2yccu4r999dA7uXO0ah9PMFFpK9yw/ugHmXQQ/z4C258I9W2HYbPBsgF0FgZt63ESgZyDvxL3jcrz4yFGOv/gtKXGB+ISX0PHbLwi65hpnpOhp0JN27a14FeVzcv6HDWJLRXJWLMcQFobPeec5jx3JOcKcv+YwccVE9qaXvcUYwsLw6t27yVp2dyXmICXExm/FvGYNYQ89hGfnztow6f7lWrRqrDl6akqaz8fVRqZsujwSjv6kHSy3b7nJ21SPtFVbLTWRexKC25etixbhdOrcmS/uPI+7Fu1g0oKt3HdpF+6/tHPdd3mzlmiDWOdNg+iL4Mvr4bs7yUvoqymFDh5ct3UagTRzMeZia+U2XZsVjqzVoqfiPO1fibn069L/S/JcXt9dnMe9XvlQvj4b0Uv7o+p9rVZrqsDh7MOsSVzDtD7T8DXWzYGF+YQx/dzpPPX7U3xx4Atu7nFzpWuE0Yjp7rsJHDuWlJdeIu2NN8hZupSIp5/Gb3A1bZS7loDQaTvwVaDAUsC6xHWsOraKTSc2UWIvoVVQJDdlpjCioIgelz6HaDuwikWreVRSDq3IYPje6XB4uVagn/gFnDPStdbSAPh7+HNrz1t586832Zm6kz4hvcj85BPS5ryN8PKi9fR7CDg6E3HgY2j/gsu9w8ddwu/f9Ob8RYtoddstDTrUasvOxrx+AyE33khmSTarjq1i+eHl7M3Yi07oMOqMzN05l/eGlf1C+Q25hPS572DNzMQQEtJgttSFuIQswgqyCPzwbbwGDiBkcunv3e5vtJmzZpyyghbsPCzJKeh8fdH7+ULGYUBAaJkmksnbxNGco3VbzNmum+h0HsbS+RFLSgqenTvTNcKfFfdfxKwf9jDnt0Nsjk/nzYl9iQquQ1E5dS/YSrSUQ9fLYcRL8NPjmNfE43Puudr30EwoE0SsYNNPj8OOCp829R7g6Q8efuAZoH0y9jFBcAfw9EPnGcAXOzMp1Plw+6W9tfTi3qWaGN+vz0CHi7X21x5jtXXQBBC9Dd7c2O3Getk9puMYfj72M3P+msMlUZfQLqBdldcZ27Qh6u23MW/cSPLzz5N4xx34Dx9OxIzprmk1KbWUVYeLtWIyUGgtZGPSRlYdW8XGpI0U2YoI9w7nunOu44roK4gJi0GXdVwroH96FUz6Uru/NqzFBP35Nr95foT3cQFDnoQL79cmwN3EpG6TWLRvEV+ufIXAH60U7d6N37DLiJw1C+EhAoIAACAASURBVGN4OPxwAP54Hwbe5vJ31aN1AK9dMoELvvwPGQs+IOLxx+r2QHMa/LMKfELB1FWbfdC7vn1l/PQjWCy8F7GX77++DJu00S2kG48OfJSRHUby3aHvmLtzLgczD3JOSKlQ4iVDSH97LuYNGwgaV2W/jtuIS8jkyb3fgt1O6xdfROhLa4Rxn0Fkby3d2Yxpsc5DGxAsN+MR2Nbljy3UO5RtydvqtljplHn5tEqZREnZoKCfp4HXr+vLxV3CeGrpbka+tZGXJsQwsnermtc/8af2f+vSfPV5Uynev5OS1HUEX+m+N4jTwSGI2LG8FPvubzTHce5UOP8e8PDXHIXBs9b18rwO8+JPBxgePZR2oT5w/r2as9+1RGuB/eEe+PER6DaSk+cMZ+WRlUzsNpEgr/rtyOZIX139w9XM2jyLhVcsRCeqjwz9LrqIjsuXk7nwI9LnzcO8cSOmadMIue1WbfYkabsmV37JE1hsFj7Z9wkLdi2gwFpAiFcI4zqPY0SHEfQL7+f6nJAOcNvP8OnV8Nk1cO3HWl2kOg79Cj89zrDMI/zhdQHnTZvn/ADjTrwxMvNgd8K/Wk+Brx9R/3uNgJEjy5oZLp0Fe3+AX57WnGA5hlx+Hmt+789ln31OyC23lO2nUxEpIWmHNlS5d6n2AcqBzgihnbCHduHPgGBW2LLp91EcvqGw0TeJyZ0mM6bjGLoEl2UTJnabyId7PuTjvR/z4kUvAuDVozuGsDDM69Y3qvOQUhL62wq6nThAxOzZeLQt/QCavFvbqfHKVxrNltOl+U2eNBKWlOSyX9r0Q85iuYMw7zByS3IpsdVhwjiwdPaxXNHcEB7ufE5FxvVrw8oHLqKDyZd7Pv+LGd/torCkhkG0E3HaJ66gsk/DZpuW0vDP+hIOr63dxkbiaHoBRr2gdVBprjb9ECx/QJtxuOIF7ROjb2idHAfgdKwrdpfr8g7tBENnwP1xcPuv0O9GOLyWj9fOALuFW1KSIOnPemtIRfhG8Nigx/gz5U8WH6h90x2dhwemaVPptFIbSEt7802OjhmLeeNGzbkZvNgSFMH4ZeN566+3iG0VyweXf8Caa9fwVOxTDIgYULWDCmgFt66EiJ7w1U3w91eVr8k8Cl9Ogs+vQaLjDtsMfu71v0ZxHEUHDnD0+utp88V6dnX3Ys4jnVwdB4B/BFz8iDbLUuH386o+bVjScwTSaiXj/SrmPiyFmpzL/Evgw2FwYCUMmAJTN8Idv8FV73J00GTmBPhyZeHf3Ja2jj+O/Mk5CTZC2xXwS1IKD+/dQJetH8D2D+DoRshLIdAjgAldJvDT0Z84aS5txNDp8BtyCfm//94wagJ15OjfB7kh7gdyew8g6PpyNbG4z7WIvPe1jWbL6dJinYc1JVWrS0hZ2qbr6jzq1a5r9AbfMJe9zHWenuhDQqrdy7x9qC9fT7uAaZd04sttiYyZ+zv7TlbTznvyLy3qKPfHaV67Ds+uXTBGd4Ult0DqgdrtbASOpptpF+Kj1XNKCjTb9B5wzUegN9Z7vbYhPvRtG8SPu6rocBJCKwiP+h8Z927hu6BgxhhMRO78Cj64VOs0Wv+Kc8OiujCu8zgubH0hb/71/+2dd3gUZdeH72dLeiWVFAglEHqA0BGQHgTEQlNBfH0tNHlBRLBiAQsqVQQVUPkQRSwUadJ7E5Ca0BIgBZIQ0utm5/tjNiE9u2E3BDP3deXKZHZmd2Z3smee55zz+83jRqpxkuJaHx/8FszH/9tvQQhuvPAilxdsYKZLQ17c8z/0kp6ven/F/J7z6VC7Q6l9JyWwqwXProe6neH3F+Goobw1JwN2zYYvO8DVPdD7PS4+sY3tuS1o4edk9HlWBiknh/gFC4l4cii6W3H4LpiP1awZHMw6x/7o/SV36DAWXOrClhlyzsuAs52W1h2asaN+R+6s+YWcKMOIPfEqbH0TPg+C9RNAlw2PfA6vXoABc0h09WNVajgjozcyOO4vlkm3qefXhY86f8AK3QgAmj85GnXdznLS+cRKeVT6/UD4vBF8UpfRYfsQkp6Vh2YXaHE59OiBPi2NjBMnLPr+5SPl5XHnnTfJVWlwenvm3aCry5ZH040HyJ9/NadGBg8pLw9dfLysa5V6U07cugUW2cYkiRKQp72Kl+safD3KwkqjYnpoEP/3fAeSM3MZsvgA3x+MLNq0lJMO8WFFSix1d+6QceIEjr17w1M/y3fxPw6T54XvM5EJhQQRN78Gcefh8W/ujs4qwcCWtTkXk1Ige1Iaqy6uIUfK47lBK+C1SzB4kdz9v2sWzG8Fy/rJXyYVjEaEEMzsPBOVUPHuwXfRS8YLGDp07YL/H2u5PqQJaTEqhixJ5NMr7VjbfzVdfStR1GDtCE+vlb9MNk2VR3BfdoA9n8h5nonHoev/OB0r55la+Jo2VWcKuoQEIoYOI2HxYpxCQ6m/cQNOffvyWMPH8HXwZeHJhSWb7bQ20PdDiL8AJ74r8tCwEH++b9ATvVCRMPtNWDUUFrSRJU7qd4dnN8pVYu3+C9aOHI09Sr+1/fj46Mfk6nOZGjKV7U9uZ0mfJQwMHELmnr+xDQ7G6okP4Ilv4KU9MCMKJp+DZ36TrXObDqF2+h1CU9P4NWoXSXPqwVddsU9ah9CqSdu6wWKKx4VJXLECu4vnWd7mcRo1L+Q9E74ZMhOhdcmCjepIjQweuoTbkJeHtnCZbrFpK3c7OXiYVK6bXDR4aD29jDIX6hrozpZJD9GlgRvvrj/HCz8cJzHfijX2H7mSy+du8Ejftw/0elmSxMUfRv4ke0r/9FSltZLMgV4vEXk7XQ4eJ1fJib9uUyGw9z09b8HU1T+lCxSk5aTxU9hP9K7bm3rO9WTp6jajYMxG+N9ZuUw1K1m+mz1dyhRQMbztvZkaMpVjN4/xS/gvRh/n0dijDNvyNFObXOLn0RL23boSsOYQ0UOGVl4GQ2sDw36QCwP+/k4OKGP+hCe+Lag2OxudjL2V2izl0aUhSRIxM94gJzISv8Vf4jvn04IqKa1ay9hWY7mQeIGd13eW3LnJILlCcOesIn4mnX1UPOdxGLsG2STvOkL2+X+g+zSYfFY+33oPFYy0ryRd4X+7/oefox9rB61l7eC1PNvsWTzsZCWIrPBwsi9exKl4b4dKJfdgNeyF1OEljrWcSfYLexnz5FoyVSp+btEf7N1Qhf+KnVs6aRvXwOeN5anCgwvhxjF5NGBGsi5eJH7+As7Ub0Ny515FGzpP/h84+shd5Q8ANTN4FDaBKhBELDbysKnEyCM5qsidi8bby2hPDzcHa5aPacc7A5uy92ICofP3cvByAkQbhtKFRh6pO3fJNerNDFarfm3hsaUQdRTWja+Su6fSiE3JIlunp5V1jDxdEPAQ9Jhxz8/r42JLSF1X/jxTenPemotrSM1N5fkWz5d80MVfbpAbe1CuXtk1y6gvhCcCn6Bj7Y588fcXFRojxWfEM23vNJ7f9jxZukwWxSfzUZMBBC7+Bv9l3yLUam689DI3xk+oXHOcWgtDlsj5nZf2QkDRUcyZ6GSa+TqjUpm3JDefO/+3ivR9+/B8fRqOpcj+P1L/EQKcAlh0alHJkZoQ0G+2HDj2fAoxp2DdeFRzmzBB9z0JjRwQ1tbEp4XCw2+UKL9OyExg3PZxWGus+bLXlwVVUoVJ2bABNBqcQkPLPIctZ28ydMkhZvx2hkbebXjI9yF+zI4i66mfYfp1HIaNIydVQ7Zje4g9LSf6l/WGj/zlUetf78gjg1L6gIxFyskhZvp0hIMjHzd5lNZ1C5Upp8TAlR0Q/JQsefQAUCODR/5oQOvlJUuxa2zBqei0Si3bWgiEab0euixIvxtstN7e5CUlGe0LIYTgP13r8fv4zthba3h62REu/L0byckXHOQEvJSTQ/q+fTg8/HBRfadmQ6DXu3B2Lez+2LhjNjMR8enYkUXP06/Jd8hPLDPbP8LAlrUJu5laQmgyOy+bledX0ql2J5q5NStjb+S70N4zZXHA4ysqfD0hBO91fg+AmQdnosvTsys8jiNXb3M5Lo3kjFxy83L54dwPDPpjEDuu7WBsq7H80eAZuqclF8iROHTpQv11f+Dx6hTS9uwh5rVpSJXx8lCp5PxOsfJUXZ6e87EpZYsh3iNZFy8SN2cODt274zqydIE+jUrDuOBxXE66zNbIrSU3qN0S2oyGw4vlJPjZ36DVCG49tZ1h6ve43GMIqVu3kXX+fJHdMnIzGL9jPHey77Co1yJ8HEr29Uh6Pcl/bsKhS5cy+zRy8/R8ujUca42K305Es/bvKJ5r/hyJWYmsu7wOVGocBsvnlmbdG/53Gl4Nh2ErZQ0yKU/u1l89QvZiqSQJS5aSff4C6RNfI1FrX9R29p/V8gxD8FOVfv6qpkYGj/wktsbbWx55uDUoIXmsVWlxtXE1bdoKiiTN83Wz8nW0jKWZjzMbJ3ZlWFt/bONPczi7LjcS5Xnt9GPH0Kenl+7d0XUyBD8Dez6Wq32qmIiENGZrv8U2NRKeXCZX3JiJJ9r64e5gxaw/zxeZW193eR0JmQkFZk/lUv9huW9i7xyjlGx9HHx4NeRVDsceZsrmpTy34hjDvz5M7y/20GbOUoKXDWDO8TnkZQTQMHcml8M7E7NrJSk2PqyN82V3eBxno5O5lanH6bnn8ZoxnbTdu0lYtKjC1zaWy/FpZOXqLRI89NnZxLw6FZWjI7VnzypXU6xfQD8aujRk8anFJTxSAOj1DjQZLPcoTbkAg+bj1agdXRq4M79WO1ROTsTPX1CweZ4+j9f3vk5YYhhzus0p88Yg4/hxdLGxRXzKi/PTsRtEJKSzcGRrOtV34+0/zuJMY1q4t+C7c9+Rp8/Dys8P68CGd6cXHb3lvFK/WfDf7XL+pON4ueT8xErj3sBCZF24QMLSpTg/Opjjfi0ACM6XzpckecqqbtciPTHVnZoZPOJuIbRa1K6ucimpW+myD262bqZNW0GRpHlBo2AlHAXtrDR8MsCPANUtjmQFMGD+PjaejiFt5y6EjQ32nTqV3EkIGDhXni5aNx6uHTL5de8F1wurGKI+iNR9hnHNbSbgaKPl1b6NORZ5h01n5PdTp9ex/OxyWrq3pJ13u4qfRAh59JGRAIe+rGhrAJ5s9CTB7iHsjF9Gx0YqFo8K5KHO27ELWIqjbR5trCfTXDOFrAxXLl29Qt3ko3yf1p6pa08zZsUxBi7cT8ePdtDorc0Muu6NCB1EwuKvSPnrr8q/GYU4HSUrNhe2MDUXcZ9/TvalS/h8NBuNm1u526qEigmtJxCZEsnGqxtLbmDvDsNXQsexYHs3sT80xI9LGYK0ISNI27OHjJMnkSSJj49+zO6o3cxoP4Pu/t3LfN2UDRsRdnZlqkqnZ+uYv/0S7evVok9TL+aPCMbOSs2E1Sd5JmgMUWlR/HVd/iwcevQg49jx0i2ItTbQ532o3wP+nCKXghuJlJdH7LszUbu44DVjBievJ+FfyxYPR0O5+vVDcqVZNe8oL06NDB65N2WfcZGXC0nXwD2w1O3cbUyQKCkYeRRqFDQ0IVbaUTDmJABPPT6EQC8HJv54gqQdO7Hv0qVsxVCNlZxwdPaXE+iJJb0qLELMKfpdn8txTRtU3aZa5CWGhfgT5O3I7E0XyMrNY2vkVqLTonm+xfNGKe0CsodFk8FyQjS94hsDlVDhkPoUIJHuspQP/nmWs8m7eaHFC+wa+Sffj/gPK8a0Z92ErmzocQu1kPjP2GnsntqDX8d2Yumotsx6rDlT+jQiNVvHp00GY9OyJbGvTyf78uUKX78izkYn42Ctod49ClEWJ23fPu78sBLXUaMKBAQroqd/T5q6NWXJP0vINdIlsV8zb5xsNPzo1xG1mxvx8+bzw/kf+Cn8J8Y0G8OIoBFl7qvPySFl61Yce/cq003ym31XSUjLZkZoEEIIPJ1smDs8mEtxaew+4Uldp7qsOLsCSZJw6N4ddDrZ5qA01Bq55NzBW06qpxk3o3Dn55/JOn0ar+mvo3Zx4eT1pALzJ0AedVg5yiOdB4gaGTx0N2/KyfI7EfI8o1sZwcMUcUQbF1lmI7lwo2DlRx6A3N8BeDbqwLzhrambHIt0MxbHiuxm7WrB078AkiyiWKjKxSJkJcMvz5IknFjj/5bFXM/UKsE7g5oSnZTJt/uusuzsMho4N6CHfw/TnqjXO3Ij2t7PKtz0xPU7bD6VQ3vnUUSmXqGFewt+H/w7r7R5BVtNse5+g4KuvW8zAtztaVu3Fv2aefN0h7q80iuQiT0D2Xk1mZgp7yLs7Lgxfjx5Kfcm1X8mOpmmPk5mTZbrEhOJmfEG1oGBeE591ej9hBBMbD2R6LRofr/8u1H72GjVDGnty4aLSdg/9zwZR46wde0c+tTtw+S2k8vdN33vXvQpKTiXMWUVn5rN13uvMqCFd5H8QrdGHozr0YA1f0fTyvFRzt8+z5GbR7ANDkbl7Fy+yq5dLRjxf3JJ7S9jKrQSzo2LI/6Ludh26siPfjfYfHkfN1Oy7trOZqfK3fPNHwOr6iMzZAw1Mnjkxt0yJMsNlVbupU9budu5k5CZYJxZjBAlej3UDvaoHBzQ3TIt51FA9El5Ss3WhTpudgxIuYSEKNfkpgC3BjB8ldyJvGa0WfyyS0WSYN14pKQbjM+ZiLtX5fs5jKFzA3f6NvXiq6MbuHTnEs+3eL5cGZFScQ+Uu9KPL4M718rcTK+XmLn+HF5O1ix8ZAKbHt/E0j5LCXAOKLmxEQq6ozvXxc/Vlg+P3MZn3jxyY2KJnjq10ja3ujw952NSaGnGfIckScS++Rb6lBR8PvsMlbVxSgD5dPHpQmvP1iz9ZylZOuMKRYaF+JOj07PK350EJ8F/Dlgzq8usCj/X5A0bUbu5lT6FCyzYcYkcnZ7X+gWVeGxy70a0D6jF7/u8cbGqxYqzKxAaDQ4PPUTa3r3lFzXUbgWDFsC1A6U6Jxbm1kcfIeXksOGx2iw+/RXTDozD1n8Zzi6GG8pzv0NuxgPT21GYGhc8JElCd/PW3WQ5lJnzcLdxJ1efS0qOkXeHLv5FEuaQ3yh4DyOPQv0dnePOc7GWP1mORjaDBXSBwQtlie6Nky1TwntkCVzYQGKnNzia16ikmq4FmBEaBC47sRXu9K/Xv3JP0n26rHi7+6MyN1n7dxSno5KZEdoEe2sN/o7+ZU+PlaOgm4+1Rs1r/RpzITaFLcIL7zffIH3vPuIXLKzUKVyKSyNbpzdrviPpp59I27ULz6mvYtO4kcn7548+4jLj+OWicT0yzXycCPTNYlXMbHb2csP3ega6feXn6/JSU0nbtUuWRSnFy+ZqfBo/Hr3OyPZ1Sr0mNWoV80cGY622Rp/clYMxBwlLDMOhRw/yEhPJOnOm/INuNRw6joMjX8E/pUvZpO3bR+rmLSSP6MPXdzYwovEIgu1HobaN5t3jLzJ512SunFwhCz36GZGzq2bUuOChT05Gys6Wda0SLoO9p9xUVgrm6DLXenmTW4ZESbmkxEJqLPi2IUuXxcz1k3C7cYXD/l7sv2Tk8QAEj4SHpsLJlXBgnnkDyI1jcj18o1D+8ZeTfZX1LTeF23lhqGyvkRTbhXBDd7XJOPtC+xflf/xb50s8nJyZyydbwmhb15VHgyswoSpFQbcsBrX0oZWfM59vC8f6sSdxGTqU20uXkrJli8mncCY/WW6mkUf2lSvc+vgT7Lt2xfWZyidv23m3o0PtDnx75lsyciv+fJKyk8h2+xqdXk/X0YvQ1q1D/PwF5d79p27bhpSTU6bp05yt4dhoVLzSq/QpaYDazrZ8MSyY6OutUWPD8rPLZXl9tZpUYwyi+rwvV0htmCT3rxRCn5nJzffeR1XXn9f8DtDcrTnT2k0jM74rDbJmMa7VOA7FHOBxdTxv+vgTnV6eQ3f1pMYFj/weD42Xt8G3vOyLK7+D1ejg4eIPWUlFykArkigpE0O+45ZbPcZsGYP2j+0AnG57lnXnjFT7zefhN6HZY7B9JnzVWU4WG5nsyydPn8epuFPsj97Pruu72Br+KxvWP8dv7j781KIvv175CSu33eyJ+5EFJxbw2bHP+OjIR7x36D3e3P8m0/ZM4419b7DhygaSs+/N033Z2WW4WLvikNuJ9zeer7wHddfJshT8jvdLPLRgxyUSM3J4b3CzipPx+Qq6LYdX+JIqleCNAU2ITc5ixcFIvN5+C9vgYGJmvEFW+EWTDv+MIVl+r66NICefo6e+hsrODp+PZlfoEV8RE4InkJiVyI9hP5a7XXZeNpN2TSI9LwFdzBj2XdLgMWEi2eHhpGzeXOZ+yRs2oq1bB5sWLUo8duL6HTafvckL3erfrWgqg4eDPHmpazMyb7dja8RWYtVp2LYOJm23EYoAaq2semznBj+PgvS7xTUJXy0hNyqKFaFW6LSCOd3nIElqzkQnE1LHh7HBY9ns1pNRKWlsSY9k4O8DmX1ktvHfNdWAGifJrisIHp5w+hIElW1X6WYrlyeaXK6bHAWeTQC5EVEXH4+UmyvbSxpL9N+csbZh0slPCDybzOMH9VgN6s8trxPcSP+EqJS2+DkZmV9QqeCxr+U741M/yqOFv96FwL5yU1Kj/nKVVhno9Dpm7JvBlshid8cOhi/VE3MBsPaEFedBIzRo1Vq0Ki1WaiusVFZYqa1IzUllw9UNaISG9rXb06tOL3rW6VnCi7s8whLD2B+9n1dav4Jdvea8+ftZtpy9SWhFsvalYVcLuk6Sg8f1w1CnIwCXbqXy/cFIRrSrc9fWtTwMCrrlXUuF6VDfjT5Nvfhq9xWGt/PHd8F8Ip94kqgJE6j3yxrULsZNS+Z7lpsjWR4/bz7ZFy7gt3gxGg+Pe36+YM9guvl1Y8XZFQxvPBxHK8cS2+glPW/uf5OTcSf5rPtnrFd78MepaKZP74f111+TsHARTv36lZiWyr11i4wjR3AfN65EYJckiY83heHuYM0LD5W06y2Nqf0ac/DaACKkg3x5YjlTe/Qg7rPPyb15E22+bUNZOHjIJcjLQ2Htc/DMb2RfjeD28uVc79qAP12vMa/LPPwc/TgdlUS2Ti8ny/N0uJ79jam+nXhm8FyWnl7KmvA1/HH5D55u8jRjmo3B2doyjZ/mouaNPPK9y51tION2uSOPSk1bQVFpdoNyry7BtDuKP6P2MKa2J36JKv63EWyaN6fehx/z34azkcjh+a0vmXYHr7GSjXn+ux3GH4POE+UE75pRsp7P5tdlHa1i6PQ63tj3BlsitzCu1ThWhq7kZ7/B/B4Vy5/1R/HXk3+xa9gumucuICB1PqdGneLk6JMcffooB0YeYNewXWx9cisbHtvAzmE7+XHAj4xuNpqo1Cg+OPwBPdf0ZPTm0Xx/7nuiUiu2mV12Zhn2WnuGBw1neH7p7ma5dLdSdBgrl15unwmShCRJvLfhPHZWaqb2NWLOPy8Xzv0GjUPBxnhV2+mhQWTm5jF/+yW0np74LVyA7uZNol81LoGea+gsb2mGfEf6wYMkLl+Oy8gRZfZLVIbxweNJyUlh5fnSm+rmnZjH1sitTGk7hX4B/RgW4k9SRi47whLwmPQKOZGRJK9bV2K/lD83gSSVOmW140IcRyMTmdQ7EHtr4+6NtWoVS0b2QqS14c+IP8huL5swGTX6ALn8e+BciNiD9Ne7xL47kzw7a95rG8kzTZ6hV51eAJy8LqsjtK7jCpe3y3p0rZ/B296bdzu9y/oh6+nh34Nvz3xL6G+hRk/73S8sGjyEEP2FEOFCiMtCiOmlPD5FCHFeCHFaCLFDCGFxMwLdrTgQAo0wlK+WkSwHcNQ6Yq22Nm3aCookzU1tFNRLeub9PY/pxBGid+KtdVrUNrb4LVyAytqaYa1CyIwazc2MaCbunGh0RUsRPBpBn/dkxdGnf5VVTI8vh6Xd4KuushRDWjx5+jze3P8mmyM3M7ntZMYGjyU4I52m+7+iYeAj1On6Gt723rjbunM9QaKBu2u5cuMqoaKFRwsmt53Mxsc28tvg3xgbPJZMXSafHf+M0N9CGbZhGEv/WcqVpCslpqOup1xn27VtDG88HCcrJzRqFW8PbMqNxExWHIg0/X0AsLKTBfmuH4JL29h2/hb7LycwuU8j3ByMqDS6slO+CTFiyqowDTwceKp9HX48ep0r8WnYBgfj9c7bpB84QPzcuRXuf+lWGjk6vXEjo3LQ3blDzPQZWDVogNe0aff0XMVp6taU3nV688P5H0jKKiorsyZ8TcGoZEyzMQB0beiOj7MNa47fwKFXL2xatCD+yy9LeMUnb9yATYsWWAUEFD2XPD2fbAmjvrs9I9r5m3Ssvi62TOv0EpLI5X/nN6L18zNNzLL109DuvyStWk7miRN830Oirn8LprSdUrDJyet38HS0xsfZRs5B2nvIo38DdZzq8Gm3T1k7aC1tPNsw/8R8Bvw2gNVhq43um6lKLBY8hBBq4EsgFGgKjBRCNC222UkgRJKklsBawOL2Wbm3bqJxd0ckGSxmy+jxALlyxN3W3fjg4eAtO5wVHnkUNApWnGNIy0lj0s5JLDu7jKHJqby5vRZ516PwnTcXbW15WsbNwZoWbm1wzxrDqbhTzNg3g7zKirWpNbLi7dDvZC2fRz6X53G3ziDviyDeWtWDTRGbmBQ8kf80/48s+b72P7Lh0OCFBaqnWbl5xCRnlrSeLQchBIGugYxtNZZfBv3Cpsc3MTVkKtZqaxadWsSQdUMY/Mdg5v09j7MJZ5EkieVnl6MRmiIe410autO7iRdf7rpMXGolFYXbjIZa9dFvn8nsjWdo5OXAMx2NvI85/TPYukKDXia/7KTegdhq1XyyWfZicR06FJeRI7j97TKS//yz3H3PRsujzpZ+lZdhlySJm++8g+7OHXw/m4PK1vyulOOCx5GRm8GKc3f1xPZG7WXWkVl08+vG9PbTC6ae1CrBk2392HspJJgCnwAAIABJREFUntjkLDwmTUIXE0vSmrtVW9lXrpB9/kKpvR2/nojiUlwar/VrjFZt+lfbqLYdqK1tw7n0LcQ1a036oUNG69IB6EKmEnemFtf8JA60VDOn+xy0hTxsTt5IonUdF0R6gmyp23J4qR43jWs1ZlGvRawMXUk953rMPjKbQX8MYt3ldZX/X7cAlhx5tAcuS5J0VZKkHOAn4NHCG0iStEuSpPxx2WHAz4LHA+SbQBmk2FWaCp3XTJIoUankKp7CXeYGR8GKynVvpN5g1OZR7Ivexxv+oYzdm0v6ict4vf469u3bF9m2Z5AnVyIaMq7lFLZf384nxz6pfNI4H7tasnfCi7vIG3uQt4M6sFGfxCuJSfx36yeyoc/a5+SGw2E/FJmiuXY7A0ninsp0/R39ebbZs6wcsJIdQ3fwVoe38Lb35rtz3zHyz5H0/bUv66+s57HAx0rkSN4YEERWbh5fbDMt4VyAWgs930IVd57WyTt5d1Az4758slNll7tmj5ebMyoLdwdrXu5en23nb3E0IhEA7xkzsG3bltg33yLrwoUy9z0dnYSjtYa6tUrvrDaGpLVrSf1rO56TJ2PTpEmln6c8Al0DCa0Xyo8XfiQhM4ELty8wdc9UGrs2Zk63OWhURaeWnmzrjyTBr39HYd+lM3YhISQsWYI+Q/6aSN6wAdRqnAYUVdDNzMnji78u0rqOC/2bV5CnKIcPekxEpclgsbiDlJVFxpEjRu8b98U8dLkwL1TDBylZ+Knlz+ZGYgbvbzjPtdsZ8pTV6Z9Br6tQjiTYM5jl/ZaztPdSnK2deevAW3x//vtKn5u5sWTw8AUK161GGdaVxfNA2eUVZkJ386ZsAnX7ErjWq9Ddzt3GhJEHGKTZCzUKurggrK3LLdc9dvMYT/35FHEZcbK5zcl4Es464jx4EK6jSl5gPYPkgOSW14tnmz7L6rDVRe7s7oU8fR7vXPqRDZk3mNBqHC888q3cL3L0G4jcBwPmgHfRCpd8kyZz9Xh42nkyPGg43/T9hj3D9/Bhlw9pUqsJ3vbePNf8uRLb1/dw4NnOAfx8/AbnYipXyRXj259zUj3esvuNLgElk7ulEvYn6DILFHQrw/Nd6+PtZMOsP8+j10sIKyv85s1F7exM1ISJ6O6Urg5wJjqFZr6VT5ZnR0Rwa/ZH2HXqSK0xz1b6+I1hbKux5Opz+fTop4zfMR5na2cW9VqEnbZk4KvjZken+m788ncUkgQek/9HXkICiatWIUkSKRs2Yt+pExr3ojcQyw9EcCslmxmhTYyXqimF9rXb0sS1BeeDwsjWWpO80ziL5/TDh0let57fO0j0CO5Dz4QYklc9y7iVR+k+Zxc/HIrk0WAfnmrvL09Z+YYUFNWUhxCCzr6d+emRn/i8++c8EVh2H1FVY8ngUdonWOrtsRDiGSAEmFPG4y8KIY4LIY7Hx9+bW17urVtovbzlHo9ykuX5eNh5mB48Ck1bCSHKbRRcE76GF7e9iKuNK6sfWU3rLC9ivj+CjZcV3u+/X+o/QjMfJ7ycrNkVHseUkCmEBoQy9++5pQvSmYBe0jPz0EzWX1nPuOBxvBQ8Fhr1k0caUy/Cc5vlKZ5i5AcPU6atjMXZ2plHGz7Kgp4L2PT4JnwdSr//eKVnIC62Wt7fULnS3Y+2XORz/QjcdTdl0yVjOP2z7Cvv38Hk18vH1krNq30b8U9UMhsNfiUaDw85gR4fT/TkKUi6oiq1uXl6LsSmVHrKSsrJIWbqa6isrPD5+ON7LsutiADnAAY3GMzmyM1k6jJZ3GsxnnaeZW4/vJ0/1xMzOBKRiF3btth3e4jb3y4jfe9ecqOjSyTKE9NzWLL7Cr2beNK+3r3ZtwoheDn4v+TaJnHC25PYrTsqvJ702dlEvfMWt1xVXBjYnMa1JrHY7mWco/fS+spiXuregH2vP8z8Ea1xun1GdgY1UQRRCEHfgL7VqgLLkldNFFA4a+UHlOiEEUL0Bt4EBkuSVKpLjyRJX0uSFCJJUojHPZQR6jMy0KekoPH0kAUDjZA/drN1Iyk7yfiElYu/3Nynu5vkkx0Fi+Y8cvW5fHj4Qz44/AGdfDqxasAqfFVuRI2fgBB5+L3YvUzxQyEEDzf2ZN/FBHR58GHXD2nv3Z63D7zNoZjKKenqJT3vHXqPPy7/wdhWYxnbamzRDexqyX7apQSzyIR03B2scLIx3aPcXDjbaZnSpxFHIhLZes60vpojV2+z4Z8YWjz0mFzOvOfTiiXbU2/B1d2yHMk93OkCPN7Gjya1nfh0SxjZOnlO27ZlS7zffZeMw4eJ++zzIttfvJV6T8ny+EVfknXuHN4ffiDL9FQBY1uNJcQrhHkPzyPQtfybtv7NvXG00bDmuHwT5jFpEvrkZKKnvY6wscGhV1FnykU7L5Oeo+P1/iVlSCpDD/8eBDgFcLFlFvZJCezecrjc7eOWLkF/PZoV/W24cvkJJv98jl+kXlz0e4IX+J3X64RT29mQTzq5UvYPav64WY71fmLJ4HEMCBRC1BNCWAEjgPWFNxBCtAaWIgeOSgpAGU+BCZSjBvKyy02W55M/v347ywRTKCRIues+p/H2LuIomJSVxMt/vczP4T8zptkYFvZciIPGntgZ08m5Folv50S0zcv3vO4Z5Elqto7jkYlYqa2Y+/Bc6jnXY/LuyYQlhhl3rAb0kp73D73Pb5d+48WWL5YMHBUQkZBeJbIkFTGyfR0CPR2YvelCwZdwRejy9Ly7/hy+Lra83KMh9JppkGxfXP6OZ3+VRTXvYcoqH7VK8MaAIKLuZPLDwbtaWy5PPI7rM8+Q+N13JK+/+6+TnyyvTGd5+pGj3P7mG1yGDsWpT597PnZjqe1QmxX9V9ChdsWjNButmsGtfNh0JpaUrFxsmzXDsW9f9MnJOPbsidrh7rV2IzGDlYcjGdrWn0AvI6cbK0AlVDzX/DkO1JfzULtW/EbUndJLZiNPnCd+6dfsbyo4oBlGgEsdvh0dws5Xe9BozFfy9NQf4yAuDHIy5Oum6aNlqlo8SFgseEiSpAMmAFuBC8AaSZLOCSHeF0Lkaw/PARyAX4QQp4QQ68t4OrOQX/GksTYMcIyZtrKtRJc5FEmaa729yI2LQ9LruZJ0hZF/juRk3Ek+7PIhr4a8ilql5vbXX5P613a8nuqJvVdOEdvZ0ujS0B0rtYqdYfI5OVk5sbjXYhy0DozbPo6YNOPkDvSSng8Of8Cvl37lhRYvMCF4gslzxhG3083S5Xyv5JfuXk/M4DsjS3dXH7tB2M1U3nykCbZWatnSt8lgOLigfMl2g4IuHiVtUSvDQ4EedG/kwcKdl0jKuDtq9Xp9Gnbt2hH79jtknjsHyB4ejjamJ8vzkpOJef11rOrWxWtGicr5asWwEH+ydXo2GHzrPSa9gtrVFZcRRUuiP9sWjlolmNzHdB2u8hhYfyBaD09i/expHX2OiatPkpsny6VIksSxyERe+uEYh6dMIEurZ3vfh/ljzMv89GInejf1knNRGmu5gVBrJ9sjnFoF2SkPnG9HWVi0w1ySpE3ApmLr3im03LvEThYkP++gVRuSqiaMPEzvMi/WKJiby76zfzLt7Cxs1DYs77ecYM9gANL27CF+/gKcBg3CtWUOnHWCWuVPqdlba+hQvxY7w+N4a6BcAe1t782S3ksYvWU0L29/mZWhK8udI5UkiVmHZ7H24lqeb/48E1tPNDlwpGblEp+aTb0q0LQyhm6NPOgZ5MnCnZd5vI1fufIUd9Jz+HxbOJ3quxFauEKn59sQthH2fQ79SxFOzFfQ7TvLrMc+Y0AQA+bvY9HOywWfqdBq8Z03l4gnhxI1bjwO3bpRPyyByVZWJMw7j7CyQmi1hX5rEVorw++761VWViT+sBJdQgIBq1eX6X9RXWjp50yQtyNrjt3g6Q51sW7QgEaHDhbZ5mx0MutOxTD+4QZ4O5fhb1NJrNRWPNP0GfYHfMaTByK5cimaTzaH0cLPmWX7IzgdlczA+P20uhnLusd8WPnCXKzUpVTcOfnAsO/h+0Gyha1rANTtYtZjvV/UKHmS/LyDRn9THjbaVyyLYXLwyJcMKdJlLicHP9/8BnWaNmFBzwV428tfVjnXrhE99TWsg4Ko/f57iB/6g0+wUZ4YvYI8mbnhPJEJ6QXJ6oauDZn/8Hxe+uslJu6cyNd9vsZGU/IfS5IkZh2ZxZqLa3iu+XNMajOpUlUqkQnycL5+NZi2yueNAU3oP28vX/x1kY8eL6l9lM8Xf10kNUvHu4ObFj13j0by3eGxb2XnO5c6RXc0QkG3MgR5O/FkWz++PxTJ6E4B1HGTv+A1bm74LVpI7Iw3SN21i+YpGdih5/bpPMg1rXnMY8oUbFs0N+txWwIhBEND/Plg43nCbqYQ5F2ye//jzWG42ml5qbtlrFuHNhrKi0FfIfanMcEhntn75d6w+u72zOpVm8bTN3LZT81T05eXHjjyqdtZtt/dNFW2ibZwgUJVUaOCh+7mTVTOzqhSr8qd5UZ8WbrZyPpWRptCaW3AwatIl/nf+ki8gc7axrwS+n2BiVBeWjpREyYg1Gr8Fi5EpVXBrXPQabxRL9UzyIuZG86zMyyO/3StV7C+nXc7Zj80m2l7pjFj3ww+6/5Zkc5vSZL46OhHBTmXyW0mV7q8MeK25SqtKktDTwdGdarL9wcjGdWxLk19Sn7xnI9JYdWRa4zuFFDqFxPdp8tBYtdH8NhXd9eboKBbGab0acyGf2L5dGsYi566O3Vp26wZ9dev42x0MsMX7mfhyNYMauWDpNcj5ebKPzk5d3+XsiysbbBtHWz2Y7YUQ4J9+HjzBX45HsXbA4v2F++9GM/+ywm8M7CpxQo1HK0cadd9BHdWf0u3xNMkD+5F27qu9GjkyV9jh2CTocPxs9ep42xEQ2m7/4J3ywqnox8k/h0h0Ehy426h9TRIsRsxZQWgVWtxsXYx3o4WDL0ecs7jYPRB3r8i+2WP8RxUEDgkSSL2jTfIvnIV37lfYOXnCzfPgj7X6AusjpsdDTzs2RVestagf0B/Xmv3WokmQkmS+OTYJ6wOW83opqOZ0nbKPdXFR8Qbgkc1yHkUZlKvQJxstXxQiuquJEnM3HAOZ1stk3uXMVdeINm+uqhke76CbjmmT/eCt7MNLzxUj42nYzl5vWSPR/FkuVCpUFlbo3ZwQFOrFlovL6z8/bFu0ACboCBsW7bELiQE+06dsGvT+p4+66rGzcGa3k28+P1kNDm6u/Lser3Ex5vD8K9ly9Md65TzDPfOM81G8U9DNdkHDzG1ZwN6BnlxYPM31NlzkSuhzejx8BjjnkgIqNOhwr6yB4kaFTx0N2+h8XSH1Jgy3QNLwySJEpCT5kk3OBV3iv/t/h/uPg1Ao0bEJRZscvubb0ndtg3PqVPvOqEZZNgLG0BVRM8gTw5fvU1atq7EY6OajirSRChJEp8e+5RVF1bxTJNnmBoy9Z6/TCJvp+PjbIONtmxNq/uBi50Vk3s34tDV2/x1vmjp7sbTsRyNSOS1fkE425Xzz5wv2b7zg7vr8hV0m5RufWoOXuzeAHcHa2ZvulAi8J2ONiTL3ap3zsJcDGvnT2J6Djsu3P0M1/0TzfnYFKb2bYy1xrLXnaedJ+quHbDKzOXW4T1E3Ykk++P53HHV0u+9by362tWdmhU8bt1Ck59YM3LkAXKvh9HTVgDOflzMuMn4HeNxt3Xnq35L0Xh4FsjBp+3bR/zcuTg98gi1nhtzd7/ov2WxNGfjVVp6BnmRmyeVaRBVuIlw7Pax/N+F/+PpJk8zrd00s9yFXk1IrzbJ8uI81aEODT0dmFWodDcjR8fsTRdo5uPE8IrE8+xqQZdXIHyTLNleSQVdU3Gw1jC5TyDHIu+wrVjgOxudTAtf5wdqBHEvdAv0wNvJpqDnIys3j8+2XqSFrzODWlZg0mUmej0xmVw1nPjjG9Z98Dy+8Xpqv/0ONsY6ev5LqTHBQ8rNRZeQgDb/e86IMt18PGw9TJq2umHrzEseLtiotHzd52vcbd3RenmRe+sWOdevE/3qVKwbN6b2hx8U/RKINtjOmvDFEBLgiqONhl1hpbfJqISKD7t+SDvvdhyIOcDIoJG83u51s3z5SJJERHxatZuyykerVvHWI024djujoH/iq91XiE3O4r3BzVAbI+3Rcaycw9o+Ey7vqJSCbmUYHuJPQ08HPt4cVlAimqPTExabalbb2eqOWiV4oq0vey7GczM5i/87fI3opEymhwaZxcfEGBr4NCe2kRtOe0/TdVsMGV1bUW/Ak1Xy2tWZGhM8dAkJIElorLMAAbWMM4qBu9NWxshexGfE82L0RnIFLG01GT9HeRSh8fYm5/o1oibI5bB+ixYWVTHNToWEiyYn1LRqFd0CPdgVHodeX/rxWamtWNRzEYt7LWZG+xlmu2u9k5FLSpauWjQIlkWPxp70aOzBgh2XOHn9Dkv3XmVIsA8hAUbKWFjZ35Vs3zK90gq6pqJRq5gRGkREQjqrj8rFFxdvpZKTpzeb7eyDwtC2/uglWHEwgkW7LtOtkQddGhpvIGYOavcdiFsqCI2GlrPmV+lrV1dqTPAoMIFSJckJba3x8tPutu5k52WTmlu+ZEVydjIv/vUit3XpfHUznoZ5d5N8Wi8vdDGxZF++jM8Xn2PlV2xqKuYUIMnGMibSM8iTuNRszsWklLmNndaOh/weMut0h7kFES3FW480ISM3j5HfHEajEkwPNVFBts2zsojmnQjZzrcSCrqVoWeQJx3r12Le9kukZOVy5h46yx9kAtzt6VCvFkv3XCU5M5fpZpIhMYUmg0eBVovvtBlVJulS3akxwaPAfla6ZVKyHIzr9cjIzWD8jvFcS7nG/K4f0yInp0ivh9ZHLuv0nDIZhy6lNAlVIlmeT4/GHghBQbd5VfGgBI+Gno6M6liXrFw9E3o2NL2hTK2F3jMBIdfpVxFCCN4c0LRA+O90VDJONhrq3IMM+4PKsBA5P/VYsG+ppdeWRuvrS6NDh3B76qkqf+3qSo3p88gPHtqcSHAzrcOzQN8q8zb1nUtOd+Xk5TB592TOJJzh8+6f06lub7lKp1CXufOjj6Lx9MSxf//SXyT6hNyMZu9m0rGBXNLYys+FneFxTOptfC7nXolMSEetEvg/AF9mr/VrTHNfZwa3qmSStdkQCLhSqc/nXmjh58yQYB+W7Y/A08maFn41J1lemEda1iYiIZ3RnS1uNlomhTW1FGrQyMO2VSvcX3gWFWkmJcvhbvCIzyhZcZWnz2PGvhkcjDnIzE4z6V3XoLhSTJpd7eKCU2ho2f/4MScqNerIp1eQJ//cSCI+tVRhYosQkZCOv6ttpVzbqhp7aw1PtvXDSnMPx1rFgSOfqf0aIwE3EjNp4VszK3xstGqm9muMp6N5ZUgUKk/1/683E7bBwXg83lkuZDJCir0wZU1bSZLEB4c/YNu1bUwNmcpjgY/dfdClqClUuaQnQNL1e+o+fdhgELW7lIZBSxFRSBZFwXL4udrxXJcAoOblOxSqLzUmeACyoB2Y1OMBsmKtVqUlIato8Jh/Yn6BGu2zzYq5sTmbEDxiTsq/72HkUdggqiqQJInI29VDir0mMLFnIK/1a0yvJmWbKCkoVCU1K3jcviIbsTiV54ZbEiEE7rbuRXo9lp9dzrKzyxjWaBgTW08suZOzH2QlQ1bZFVAFRJ8AhCyIWEnyDaL2XkwoIuVgKeJSs8nIyatWgoj/ZhysNYx/uGG16+RXqLnUsOBxSRZErISqpbute0HO49eLvzL377n0D+jPGx3eKD2P4VJSmr1MYk6AeyOwvjczm55BnqQZDKIszdX46ieIqKCgUHXUrOCRcMnkMt183G3dSchKYFvkNt4//D5dfLswu+vsImq1RXA2CLYlVRA8JEkeeZhBbbO4QZQlibz9YJTpKigoWIaaEzx02ZB0TR55VAJ3W3euJV/j9X2v08qjFXN7zEVbnkKmsSOPlGhIj7unfEc+hQ2iLE1EQjpWGhU+zsY3WyooKPx7qDnBIzFC9pw2MVmej7utOzn6HOo712dRr0UF0uplYu8JaquKg0e0oTnQTDr/vYI8uRqfTqShgc9SRCSkE+BmV2X6QgoKCtWLmhM8bl+Wf1dy2qqzT2e6+nZlaZ+lOFkZ0eGqUsmJ+YqmrWJOgEoDXuZxd+sZJEsnWHrqSg4eypSVgkJNxaLBQwjRXwgRLoS4LISYXsrj3YQQJ4QQOiGEZWUqb1euTDefYM9gvur9VUHPh1EY0+sR/Td4NZMdCM1AeQZR5iJPL3H9dka1lWJXUFCwPBYLHkIINfAlEAo0BUYKIZoW2+w6MAb40VLHUUCLoTDyJ4v6MJTAuU75Iw+9XhZENEO+ozC9mniVaRBlDmKSMsnJ01NPGXkoKNRYLDnyaA9cliTpqiRJOcBPwKOFN5AkKVKSpNOA5RsTnP1kE5+qxMUf0m7KyfrSSLwC2Slm9zV+uLFnuQZR98rVB0QQUUFBwXJYMnj4AoVvu6MM62oOzoaKq5To0h+PrrySbnlUZBB1r0QqwUNBocZjyeBRWhlOxW5KpT2REC8KIY4LIY7Hx5tgB3u/ybeTLWvqKuaE3PHuYV5/gnyDqJ3lGETdCxEJ6dhbqfFwtDb7cysoKDwYWDJ4RAGFTaL9gJjKPJEkSV9LkhQiSVKIh4eHWQ6uSqio1yP6hCxJoja/Mn7PIE/iKzCIqiz5gog1URpcQUFBxpLB4xgQKISoJ4SwAkYA6y34etUPJz9AlD7yyMuFm6fNPmWVjyUNoiISFEFEBYWajsWChyRJOmACsBW4AKyRJOmcEOJ9IcRgACFEOyFEFDAUWCqEOGep47kvaKzA0RuSo0o+FncBdFlmT5bnU9ggypzk6PRE3clQgoeCQg3Hok6CkiRtAjYVW/dOoeVjyNNZ/16c/SH5esn1BbazrS320r2CPPn8r4vEp2abLT9xPTEDvaQkyxUUajo1p8P8fuHsV/q0VfQJsHGBWiVtbc2FJQyilEorBQUFUIKH5XHxl0t19cVaWWJOyKMOCyadLWEQFaEEDwUFBZTgYXmc/SEvB9Ju3V2Xmwm3zlss35GPEIKeQeY1iIq4nY6rnRYXOyuzPJ+CgsKDiRI8LI2LwdejcNL85hmQ8ixWaVWYhxub1yAqIl7xLVdQUFCCh+XJbxQsnDQ3swx7eZjbIErxLVdQUAAleFiefImSwknzmBPg4A1OPhZ/+QKDKDMEj8ycPGKTsxRBRAUFBSV4WBwbJ7BxLtplbibbWWPpFeTJ1YR7N4gqsJ5VpNgVFGo8SvCoCpzr3M15ZCbJ3iJVkO/Ix1wGUfmVVooJlIKCghI8qgIX/7vTVrGn5N++lmsOLI65DKKUMl0FBYV8lOBRFTj73Z22spAMe0XkG0TN2RrG8chE8iqhthuRkI6nozX21hYVJlBQUHgAUL4FqgJnf9n0KTNJTpa7BoBdrSo9hGc7B3AmKpkle67y5a4ruNhp6d7Ig55BnnQL9MDVvuK+DUUQUUFBIR8leFQFhaXZo0+Cf/sqPwRfF1tWv9iR5Mxc9l2KZ2dYHHvC41l3KgaVgNZ1XOkZ5EmPxh40re1Uqtx6ZEI6fZp6VfmxKygoVD+U4FEVOBsaBaNPQEoU+L58/w7FVsvAlj4MbOmDXi9xOjqZnWFx7A6PY87WcOZsDcfbyYaHgzx4uLEnXRq6Y2+tITkzl9vpOcrIQ0FBAVCCR9WQP/K4YLAz8W17/46lECqVINjfhWB/F6b0aURcaha7w+PZFRbHhn9iWX30BlZqFR3q1yLQ0xFQkuUKCgoySvCoCuzcQW0NV3eDUEHtVvf7iErF09GGYSH+DAvxJ0en5/i1RHaFxbErPJ59lxIAaOjpcJ+PUkFBoTqgBI+qQKWSK64Sr4BnU7Cq/nfvVhoVnRu407mBO28+AtdvZxCTnEl9DyV4KCgoKKW6VUf+1FUVl+iaizpudnSs73a/D0NBQaGaoASPqiJf46oKmwMVFBQULIUSPKqKfGn2B3TkoaCgoFAYiwYPIUR/IUS4EOKyEGJ6KY9bCyF+Njx+RAgRYMnjua8EDYQ2o8G7xf0+EgUFBYV7xmLBQwihBr4EQoGmwEghRNNimz0P3JEkqSEwF/jEUsdz3/FqCoMXglp7v49EQUFB4Z6x5MijPXBZkqSrkiTlAD8Bjxbb5lHge8PyWqCXKK21WUFBQUGhWmHJ4OELFDKxIMqwrtRtJEnSAcmAUtKjoKCgUM2xZPAobQRRXMrVmG0QQrwohDguhDgeHx9vloNTUFBQUKg8lgweUYB/ob/9gJiythFCaABnILH4E0mS9LUkSSGSJIV4eHhY6HAVFBQUFIzFksHjGBAohKgnhLACRgDri22zHnjWsPwksFOSJNONJhQUFBQUqhSLyZNIkqQTQkwAtgJqYLkkSeeEEO8DxyVJWg8sA1YKIS4jjzhGWOp4FBQUFBTMh0W1rSRJ2gRsKrbunULLWcBQSx6DgoKCgoL5UTrMFRQUFBRMRjxoKQYhRDxwzYRd3IEECx3Og4By/sr5K+dfcyl8/nUlSTJbxdEDFzxMRQhxXJKkkPt9HPcL5fyV81fOXzl/Szy3Mm2loKCgoGAySvBQUFBQUDCZmhA8vr7fB3CfUc6/ZqOcf83GYuf/r895KCgoKCiYn5ow8lBQUFBQMDP/6uBRkRnVg4gQwl8IsUsIcUEIcU4IMcmwvpYQ4i8hxCXDb1fDeiGEWGB4D04LIdoUeq5nDdtfEkI8W9ZrVkeEEGohxEkhxEbD3/UMhmKXDAZjVob1ZRqOCSFmGNaHCyH63Z8zqRxCCBchxFohRJjhWuhUk64BIcRkw/V/VgixWghh82++BoQQy4UQcUKIs4XWme3zFkK0FUKcMeyzQAgjrDEkSfpX/iBLolwB6gNWwD9A0/t9XGY4r9pAG8OyI3AR2WzrU2C6Yf1xgKwPAAAFjUlEQVR04BPD8gBgM7KCcUfgiGF9LeCq4berYdn1fp+fCe/DFOBHYKPh7zXACMPyEmCsYXkcsMSwPAL42bDc1HBNWAP1DNeK+n6flwnn/z3wX8OyFeBSU64BZCuHCMC20Gc/5t98DQDdgDbA2ULrzPZ5A0eBToZ9NgOhFR7T/X5TLPhmdwK2Fvp7BjDjfh+XBc5zHdAHCAdqG9bVBsINy0uBkYW2Dzc8PhJYWmh9ke2q8w+yQvMOoCew0XDBJwCa4p89srZaJ8OyxrCdKH49FN6uuv8AToYvT1FsfY24BrjrA1TL8JluBPr9268BIKBY8DDL5214LKzQ+iLblfXzb562MsaM6oHGMPxuDRwBvCRJigUw/PY0bFbW+/Agvz/zgGmA3vC3G5AkyYZiUPRcyjIce5DPvz4QD6wwTN19K4Swp4ZcA5IkRQOfAdeBWOTP9G9q1jUA5vu8fQ3LxdeXy785eBhlNPWgIoRwAH4F/idJUkp5m5ayTipnfbVGCDEQiJMk6e/Cq0vZVKrgsQfy/A1okKcwvpIkqTWQjjxtURb/qvfAMLf/KPJUkw9gD4SWsum/+RooD1PPt1Lvw785eBhjRvVAIoTQIgeOVZIk/WZYfUsIUdvweG0gzrC+rPfhQX1/ugCDhRCRwE/IU1fzABchG4pB0XMpy3DsQT1/kI89SpKkI4a/1yIHk5pyDfQGIiRJipckKRf4DehMzboGwHyfd5Rhufj6cvk3Bw9jzKgeOAxVEMuAC5IkfVHoocLGWs8i50Ly1482VGB0BJINQ9ytQF8hhKvhTq6vYV21RpKkGZIk+UmSFID8me6UJOlpYBeyoRiUPP/SDMfWAyMMlTj1gEDkpGG1R5Kkm8ANIURjw6pewHlqyDWAPF3VUQhhZ/h/yD//GnMNGDDL5214LFUI0dHwfo4u9Fxlc7+TQBZOMA1Arka6Arx5v4/HTOfUFXlIeRo4ZfgZgDyHuwO4ZPhdy7C9AL40vAdngJBCz/Uf4LLh57n7fW6VeC96cLfaqj7yP/5l4BfA2rDexvD3ZcPj9Qvt/6bhfQnHiOqS6vQDBAPHDdfBH8jVMzXmGgDeA8KAs8BK5Iqpf+01AKxGzu/kIo8Unjfn5w2EGN7LK8AiihVjlPajdJgrKCgoKJjMv3naSkFBQUHBQijBQ0FBQUHBZJTgoaCgoKBgMkrwUFBQUFAwGSV4KCgoKCiYjBI8FBQUFBRMRgkeCgomIoQYI4TwqcR+LwshRhuWvxNCPFnRPgoK1RVNxZsoKCgUYwxyQ1UJCQchhFqSpLzSdpIkaYmFj0tBocpQRh4KCsgKxUI2VfrGYDK0TQhhW8p2TyJ3464SQpwSQtgKISKFEO8IIfYDQ4UQLwghjgkh/hFC/CqEsDPsO1MIMbWU5/xYCHHeYNzzmcVPVkHBDCjBQ0HhLoHAl5IkNQOSgCeKbyBJ0lpkWZCnJUkKliQp0/BQliRJXSVJ+gn4TZKkdpIktQIuIEtJlIoQohbwGNBMkqSWwIfmPSUFBcugBA8FhbtESJJ0yrD8N7L5jrH8XGi5uRBinxDiDPA00Kyc/VKALOBbIcTjQIYJr6mgcN9QgoeCwl2yCy3nYVpOML3Q8nfABEmSWiAL+NmUtZMkmxO1R5bYHwJsMeE1FRTuG0rCXEHBdFKR/ePLwhGINfiuPA1El7WhwdTLTpKkTUKIw8hqpwoK1R4leCgomM53wBIhRCayV3Zx3ka2Br6GLIldUaBZJ4SwQZbSnmzeQ1VQsAyKJLuCgoKCgskoOQ8FBQUFBZNRpq0UFMpACPElsmd6YeZLkrTifhyPgkJ1Qpm2UlBQUFAwGWXaSkFBQUHBZJTgoaCgoKBgMkrwUFBQUFAwGSV4KCgoKCiYjBI8FBQUFBRM5v8BeVdz9NBZIQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "mc_trails = performance_df2[performance_df2[\"method\"]==\"MC\"][\"n_trails\"]\n",
    "mc_err = performance_df2[performance_df2[\"method\"]==\"MC\"][\"err\"]\n",
    "ax.plot(mc_trails,mc_err,label=\"regular MC\")\n",
    "\n",
    "anti_mc_trails = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"n_trails\"]\n",
    "anti_mc_err = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"err\"]\n",
    "ax.plot(anti_mc_trails,anti_mc_err,label=\"antithetic regular MC\")\n",
    "\n",
    "ohmc_trails = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"n_trails\"]\n",
    "ohmc_err = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"err\"]\n",
    "ax.plot(ohmc_trails,ohmc_err,label=\"OHMC\")\n",
    "\n",
    "anti_ohmc_trails = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"n_trails\"]\n",
    "anti_ohmc_err = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"err\"]\n",
    "ax.plot(anti_ohmc_trails,anti_ohmc_err,label=\"antithetic OHMC\")\n",
    "\n",
    "ax.legend()\n",
    "plt.xlabel(\"n_trails\")\n",
    "plt.ylabel(\"err\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Runtime Efficiency Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "mc_runtime = performance_df2[performance_df2[\"method\"]==\"MC\"][\"runtime\"]\n",
    "mc_err = performance_df2[performance_df2[\"method\"]==\"MC\"][\"err\"]\n",
    "ax.scatter(mc_runtime,mc_err,label=\"regular MC\")\n",
    "\n",
    "anti_mc_runtime = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"runtime\"]\n",
    "anti_mc_err = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"err\"]\n",
    "ax.scatter(mc_runtime,mc_err,label=\"antithetic regular MC\")\n",
    "\n",
    "ohmc_runtime = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"runtime\"]\n",
    "ohmc_err = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"err\"]\n",
    "ax.scatter(ohmc_runtime,ohmc_err,label=\"OHMC\")\n",
    "\n",
    "anti_ohmc_runtime = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"runtime\"]\n",
    "anti_ohmc_err = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"err\"]\n",
    "ax.scatter(ohmc_runtime,ohmc_err,label=\"antithetic OHMC\")\n",
    "\n",
    "ax.legend()\n",
    "plt.xlabel(\"runtime\")\n",
    "plt.ylabel(\"err\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Conclusion\n",
    "\n",
    "From the test, one can see OHMC reduce the variance considerably, which make it more appreciable when number of trails is limited. For example, if we can only make trails less than 1000, OHMC is definite better than regular MC. However the runtime efficiency is similar based our observation. It seems slightly stable than regular MC, but still not enough to affirm that. As for the antithetic variates' version, there is no promotion in time efficiency and the variance reduction effect is valid only when number of trajectories is small enough and not gauranteed. Therefore, the antithetic variates method is not effective enough, the delta-based method is neither time efficient nor practical. At last, we highly recommand the optimal hedged Monte Carlo simulation as it is efficient, accurate and compatible to most of the stochastic process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Boundary Scheme Test\n",
    "\n",
    "Five kinds of boundary scheme:\n",
    "\n",
    "* absorption\n",
    "* reflection\n",
    "* Higham and Mao\n",
    "* partial truncation\n",
    "* full truncation\n",
    "\n",
    "We used Euler discretization schemes as presented in Table 1 of the paper \n",
    "\n",
    "Lord, Roger, Remmert Koekkoek, and Dick Van Dijk. A comparison of biased simulation schemes for stochastic volatility models. Quantitative Finance 10.2 (2010): 177-194.\n",
    "\n",
    "https://www.ssoar.info/ssoar/bitstream/handle/document/22127/ssoar-2010-02-lord_et_al-a_comparison_of_biased_simulation.pdf?sequence=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_scheme_comparison(n_trails,n_steps,boundarySchemes):\n",
    "    simulation_start = timeit.default_timer()\n",
    "    mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "    simulation_end = timeit.default_timer()\n",
    "    theoretical_value = 6.8061\n",
    "    \n",
    "    se_estimate_list = []\n",
    "    rmse_list = []\n",
    "    abs_err_list = []\n",
    "    runtime_list = []\n",
    "    \n",
    "    for boundaryScheme in boundarySchemes:\n",
    "        # regular MC\n",
    "        rmc_start = timeit.default_timer()\n",
    "        mc.simulate(n_trails,n_steps,boundaryScheme=boundaryScheme)\n",
    "        rmc_price = mc.MCPricer('c')\n",
    "        rmc_end = timeit.default_timer()\n",
    "        \n",
    "        rmc_se_estimate = mc.standard_error()\n",
    "        rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "        rmc_runtime = rmc_end-rmc_start + simulation_end - simulation_start\n",
    "        rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "        se_estimate_list.append(rmc_se_estimate)\n",
    "        rmse_list.append(rmc_rmse)\n",
    "        abs_err_list.append(rmc_err)\n",
    "        runtime_list.append(rmc_runtime)\n",
    "        \n",
    "    result = {\"boundary scheme\": boundarySchemes,\n",
    "              \"n_trials\": [n_trails]*len(boundarySchemes),\n",
    "              \"n_steps\": [n_steps]*len(boundarySchemes),\n",
    "              \"runtime\": runtime_list,\n",
    "              \"abs err\": abs_err_list,\n",
    "              \"root mean square err\": rmse_list,\n",
    "              \"standard err estimate\": se_estimate_list\n",
    "             }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trials: 100; n_steps: 50\n",
      "n_trials: 100; n_steps: 100\n",
      "n_trials: 100; n_steps: 150\n",
      "n_trials: 600; n_steps: 50\n",
      "n_trials: 600; n_steps: 100\n",
      "n_trials: 600; n_steps: 150\n"
     ]
    }
   ],
   "source": [
    "n_trails_list = np.arange(100,1000,500)\n",
    "n_steps_list = np.arange(50,200,50)\n",
    "boundarySchemes = [\"absorption\", \"reflection\", \"Higham and Mao\", \"partial truncation\", \"full truncation\"]\n",
    "boundary_scheme_df = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "    for n_steps in n_steps_list:\n",
    "        print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "        new_df = pd.DataFrame(boundary_scheme_comparison(n_trails,n_steps,boundarySchemes))\n",
    "        boundary_scheme_df = pd.concat((boundary_scheme_df,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "      <th>abs err</th>\n",
       "      <th>root mean square err</th>\n",
       "      <th>standard err estimate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boundary scheme</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_trials</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Higham and Mao</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.031220</td>\n",
       "      <td>8.346140</td>\n",
       "      <td>0.838813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.853895</td>\n",
       "      <td>8.771608</td>\n",
       "      <td>0.356696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.651469</td>\n",
       "      <td>7.439677</td>\n",
       "      <td>0.744843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.307896</td>\n",
       "      <td>7.918233</td>\n",
       "      <td>0.323286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.057177</td>\n",
       "      <td>8.029530</td>\n",
       "      <td>0.806978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.759660</td>\n",
       "      <td>8.355829</td>\n",
       "      <td>0.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">absorption</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.585880</td>\n",
       "      <td>8.548298</td>\n",
       "      <td>0.857116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.308735</td>\n",
       "      <td>8.059897</td>\n",
       "      <td>0.329077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.004175</td>\n",
       "      <td>1.048118</td>\n",
       "      <td>7.654053</td>\n",
       "      <td>0.762015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.772224</td>\n",
       "      <td>7.961284</td>\n",
       "      <td>0.323755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.688101</td>\n",
       "      <td>7.594825</td>\n",
       "      <td>0.760169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.300334</td>\n",
       "      <td>7.676816</td>\n",
       "      <td>0.313426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">full truncation</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.627003</td>\n",
       "      <td>7.104788</td>\n",
       "      <td>0.711272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.270499</td>\n",
       "      <td>8.293457</td>\n",
       "      <td>0.338681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>7.378325</td>\n",
       "      <td>0.740985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.349177</td>\n",
       "      <td>7.803851</td>\n",
       "      <td>0.318537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.006873</td>\n",
       "      <td>1.563819</td>\n",
       "      <td>7.142353</td>\n",
       "      <td>0.700416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>7.651811</td>\n",
       "      <td>0.312629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">partial truncation</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.081172</td>\n",
       "      <td>7.477785</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.741581</td>\n",
       "      <td>8.251383</td>\n",
       "      <td>0.335778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.004095</td>\n",
       "      <td>1.383946</td>\n",
       "      <td>8.812268</td>\n",
       "      <td>0.874676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.710740</td>\n",
       "      <td>8.300591</td>\n",
       "      <td>0.337907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.007213</td>\n",
       "      <td>0.080982</td>\n",
       "      <td>7.460196</td>\n",
       "      <td>0.749734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.015550</td>\n",
       "      <td>0.334756</td>\n",
       "      <td>7.848708</td>\n",
       "      <td>0.320398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">reflection</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>100</th>\n",
       "      <td>0.002101</td>\n",
       "      <td>2.965322</td>\n",
       "      <td>10.919870</td>\n",
       "      <td>1.056248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.405092</td>\n",
       "      <td>8.699405</td>\n",
       "      <td>0.355062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>100</th>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.688402</td>\n",
       "      <td>8.000196</td>\n",
       "      <td>0.801068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.400987</td>\n",
       "      <td>8.121465</td>\n",
       "      <td>0.331429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">150</th>\n",
       "      <th>100</th>\n",
       "      <td>0.005926</td>\n",
       "      <td>1.485519</td>\n",
       "      <td>8.263816</td>\n",
       "      <td>0.817015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.014480</td>\n",
       "      <td>1.013575</td>\n",
       "      <td>8.375758</td>\n",
       "      <td>0.339709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      runtime   abs err  root mean square err  \\\n",
       "boundary scheme    n_steps n_trials                                             \n",
       "Higham and Mao     50      100       0.002314  0.031220              8.346140   \n",
       "                           600       0.004513  0.853895              8.771608   \n",
       "                   100     100       0.003462  0.651469              7.439677   \n",
       "                           600       0.008513  0.307896              7.918233   \n",
       "                   150     100       0.008439  0.057177              8.029530   \n",
       "                           600       0.014305  0.759660              8.355829   \n",
       "absorption         50      100       0.003670  0.585880              8.548298   \n",
       "                           600       0.005009  0.308735              8.059897   \n",
       "                   100     100       0.004175  1.048118              7.654053   \n",
       "                           600       0.010287  0.772224              7.961284   \n",
       "                   150     100       0.005694  0.688101              7.594825   \n",
       "                           600       0.016005  0.300334              7.676816   \n",
       "full truncation    50      100       0.002321  0.627003              7.104788   \n",
       "                           600       0.004636  0.270499              8.293457   \n",
       "                   100     100       0.004036  0.287766              7.378325   \n",
       "                           600       0.008946  0.349177              7.803851   \n",
       "                   150     100       0.006873  1.563819              7.142353   \n",
       "                           600       0.016905  0.075221              7.651811   \n",
       "partial truncation 50      100       0.002006  0.081172              7.477785   \n",
       "                           600       0.004817  0.741581              8.251383   \n",
       "                   100     100       0.004095  1.383946              8.812268   \n",
       "                           600       0.008983  0.710740              8.300591   \n",
       "                   150     100       0.007213  0.080982              7.460196   \n",
       "                           600       0.015550  0.334756              7.848708   \n",
       "reflection         50      100       0.002101  2.965322             10.919870   \n",
       "                           600       0.004956  0.405092              8.699405   \n",
       "                   100     100       0.003713  0.688402              8.000196   \n",
       "                           600       0.008853  0.400987              8.121465   \n",
       "                   150     100       0.005926  1.485519              8.263816   \n",
       "                           600       0.014480  1.013575              8.375758   \n",
       "\n",
       "                                     standard err estimate  \n",
       "boundary scheme    n_steps n_trials                         \n",
       "Higham and Mao     50      100                    0.838813  \n",
       "                           600                    0.356696  \n",
       "                   100     100                    0.744843  \n",
       "                           600                    0.323286  \n",
       "                   150     100                    0.806978  \n",
       "                           600                    0.339996  \n",
       "absorption         50      100                    0.857116  \n",
       "                           600                    0.329077  \n",
       "                   100     100                    0.762015  \n",
       "                           600                    0.323755  \n",
       "                   150     100                    0.760169  \n",
       "                           600                    0.313426  \n",
       "full truncation    50      100                    0.711272  \n",
       "                           600                    0.338681  \n",
       "                   100     100                    0.740985  \n",
       "                           600                    0.318537  \n",
       "                   150     100                    0.700416  \n",
       "                           600                    0.312629  \n",
       "partial truncation 50      100                    0.751501  \n",
       "                           600                    0.335778  \n",
       "                   100     100                    0.874676  \n",
       "                           600                    0.337907  \n",
       "                   150     100                    0.749734  \n",
       "                           600                    0.320398  \n",
       "reflection         50      100                    1.056248  \n",
       "                           600                    0.355062  \n",
       "                   100     100                    0.801068  \n",
       "                           600                    0.331429  \n",
       "                   150     100                    0.817015  \n",
       "                           600                    0.339709  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_boundary_scheme_df = boundary_scheme_df.set_index(['boundary scheme','n_steps','n_trials']).sort_index()\n",
    "sorted_boundary_scheme_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the above form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_trials</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>runtime</th>\n",
       "      <th>abs err</th>\n",
       "      <th>root mean square err</th>\n",
       "      <th>standard err estimate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boundary scheme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Higham and Mao</th>\n",
       "      <td>350.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.443553</td>\n",
       "      <td>8.143503</td>\n",
       "      <td>0.568435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorption</th>\n",
       "      <td>350.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.617232</td>\n",
       "      <td>7.915862</td>\n",
       "      <td>0.557593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full truncation</th>\n",
       "      <td>350.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.528914</td>\n",
       "      <td>7.562431</td>\n",
       "      <td>0.520420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial truncation</th>\n",
       "      <td>350.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.555530</td>\n",
       "      <td>8.025155</td>\n",
       "      <td>0.561666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflection</th>\n",
       "      <td>350.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>1.159816</td>\n",
       "      <td>8.730085</td>\n",
       "      <td>0.616755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_trials  n_steps   runtime   abs err  \\\n",
       "boundary scheme                                             \n",
       "Higham and Mao         350.0    100.0  0.006924  0.443553   \n",
       "absorption             350.0    100.0  0.007473  0.617232   \n",
       "full truncation        350.0    100.0  0.007286  0.528914   \n",
       "partial truncation     350.0    100.0  0.007111  0.555530   \n",
       "reflection             350.0    100.0  0.006671  1.159816   \n",
       "\n",
       "                    root mean square err  standard err estimate  \n",
       "boundary scheme                                                  \n",
       "Higham and Mao                  8.143503               0.568435  \n",
       "absorption                      7.915862               0.557593  \n",
       "full truncation                 7.562431               0.520420  \n",
       "partial truncation              8.025155               0.561666  \n",
       "reflection                      8.730085               0.616755  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_scheme_df.groupby(\"boundary scheme\").apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the absolute error, Higham and Mao's scheme works the best and the reflection scheme performs the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
